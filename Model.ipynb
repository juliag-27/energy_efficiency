{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"VG48MofoC7_-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745958523686,"user_tz":240,"elapsed":60680,"user":{"displayName":"Eric Zheng","userId":"09751706780638879012"}},"outputId":"3512561f-5cf3-42f4-c289-582726c5ad5f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import numpy as np\n","import torch\n","from torch.utils.data import Dataset, DataLoader, TensorDataset\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.metrics import precision_recall_fscore_support\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# neural network\n","class EnergyEfficiencyMLP(nn.Module):\n","    def __init__(self, input_dim):\n","        super(EnergyEfficiencyMLP, self).__init__()\n","        # 8 neurons with relu and 50% dropout -> binary classification\n","        self.mlp = nn.Sequential(\n","            nn.Linear(input_dim, 8),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(8, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        return self.mlp(x)"],"metadata":{"id":"8oOF1D3MXv2j","executionInfo":{"status":"ok","timestamp":1745958530177,"user_tz":240,"elapsed":2,"user":{"displayName":"Eric Zheng","userId":"09751706780638879012"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["def get_loaders(ablation_type):\n","  # create paths\n","  BASE_PATH = '/content/drive/MyDrive/semester 4/csci 1470: final project/ablation_datasets/'\n","  TRAIN_DATA_PATH = BASE_PATH + ablation_type + '/train_dataset.npz'\n","  VAL_DATA_PATH = BASE_PATH + ablation_type + '/val_dataset.npz'\n","  TEST_DATA_PATH = BASE_PATH + ablation_type + '/test_dataset.npz'\n","\n","  # load data from paths\n","  train_data = np.load(TRAIN_DATA_PATH)\n","  val_data = np.load(VAL_DATA_PATH)\n","  test_data = np.load(TEST_DATA_PATH)\n","\n","  # get numpy arrays from compressed data\n","  X_train, y_train = train_data['X.npy'], train_data['y.npy']\n","  X_val, y_val = val_data['X.npy'], val_data['y.npy']\n","  X_test, y_test = test_data['X.npy'], test_data['y.npy']\n","\n","  print(f\"Training data shape: {X_train.shape}\")\n","  print(f\"Training labels shape: {y_train.shape}\")\n","  print(f\"Validation data shape: {X_val.shape}\")\n","  print(f\"Test data shape: {X_test.shape}\")\n","\n","  # convert numpy arrays to PyTorch tensors\n","  X_train_tensor = torch.FloatTensor(X_train)\n","  y_train_tensor = torch.FloatTensor(y_train)\n","  X_val_tensor = torch.FloatTensor(X_val)\n","  y_val_tensor = torch.FloatTensor(y_val)\n","  X_test_tensor = torch.FloatTensor(X_test)\n","  y_test_tensor = torch.FloatTensor(y_test)\n","\n","  # create datasets\n","  train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n","  val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n","  test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n","\n","  # create data loaders with batch size 16\n","  batch_size = 16\n","  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","  val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","  test_loader = DataLoader(test_dataset, batch_size=batch_size)\n","\n","  # return data and loaders\n","  return {\"data\": (X_train, y_train), \"loaders\": (train_loader, val_loader, test_loader)}"],"metadata":{"id":"nuIVRhswLKgr","executionInfo":{"status":"ok","timestamp":1745958833293,"user_tz":240,"elapsed":9,"user":{"displayName":"Eric Zheng","userId":"09751706780638879012"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def train_model(y_train, train_loader, val_loader, test_loader, input_dim, device=None):\n","    if device is None:\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # initialize model\n","    model = EnergyEfficiencyMLP(input_dim).to(device)\n","\n","    # calculate class weights - make sure each class are equally important\n","    num_efficient = np.sum(y_train == 1)\n","    num_inefficient = np.sum(y_train == 0)\n","    total = num_efficient + num_inefficient\n","\n","    weight_efficient = total / (2 * num_efficient)\n","    weight_inefficient = total / (2 * num_inefficient)\n","\n","    print(f\"distribution: efficient={num_efficient}, inefficient={num_inefficient}\")\n","    print(f\"weights: efficient={weight_efficient:.4f}, inefficient={weight_inefficient:.4f}\")\n","\n","    # adam optimizer with learning rate 0.0001\n","    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","\n","    # training loop\n","    num_epochs = 30\n","    best_val_f1 = 0\n","    best_model = None\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        train_loss = 0.0\n","\n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            # forward pass\n","            outputs = model(inputs).squeeze()\n","\n","            # calculate loss with class weights\n","            weights = torch.where(labels == 1,\n","                               torch.tensor(weight_efficient, device=device),\n","                               torch.tensor(weight_inefficient, device=device))\n","\n","            criterion = nn.BCELoss(weight=weights)\n","            loss = criterion(outputs, labels)\n","\n","            # backward pass and optimize\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item() * inputs.size(0)\n","\n","        train_loss = train_loss / len(train_loader.dataset)\n","\n","        # evaluate on validation set\n","        val_loss, val_metrics = evaluate_model(model, val_loader, device)\n","\n","        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f}\")\n","        print(f\"Val Metrics: Precision={val_metrics['precision']:.4f}, Recall={val_metrics['recall']:.4f}, F1={val_metrics['f1']:.4f}\")\n","\n","        # save best model based on validation F1 score\n","        if val_metrics['f1'] > best_val_f1:\n","            best_val_f1 = val_metrics['f1']\n","            best_model = model.state_dict().copy()\n","\n","    # load best model\n","    model.load_state_dict(best_model)\n","\n","    # evaluation on test set\n","    test_loss, test_metrics = evaluate_model(model, test_loader, device)\n","\n","    print(\"\\nTest Results:\")\n","    print(f\"Loss: {test_loss:.4f}\")\n","    print(f\"Precision: {test_metrics['precision']:.4f}\")\n","    print(f\"Recall: {test_metrics['recall']:.4f}\")\n","    print(f\"F1 Score: {test_metrics['f1']:.4f}\")\n","\n","    return model, test_metrics\n","\n","\n","def evaluate_model(model, data_loader, device):\n","    model.eval()\n","    running_loss = 0.0\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for inputs, labels in data_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            # forward pass + remove dim of 1\n","            outputs = model(inputs).squeeze()\n","\n","            # binary cross entrpy\n","            criterion = nn.BCELoss()\n","            loss = criterion(outputs, labels)\n","\n","            running_loss += loss.item() * inputs.size(0)\n","\n","            # convert outputs to binary predictions\n","            preds = (outputs > 0.5).float()\n","\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    # calculate loss\n","    loss = running_loss / len(data_loader.dataset)\n","\n","    # calculate metrics\n","    precision, recall, f1, _ = precision_recall_fscore_support(\n","        all_labels, all_preds, average='macro', zero_division=0)\n","\n","    metrics = {\n","        'precision': precision,\n","        'recall': recall,\n","        'f1': f1\n","    }\n","\n","    return loss, metrics\n"],"metadata":{"id":"Fg4RH6u6YZkc","executionInfo":{"status":"ok","timestamp":1745958832618,"user_tz":240,"elapsed":22,"user":{"displayName":"Eric Zheng","userId":"09751706780638879012"}}},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["**Train MLP Model**"],"metadata":{"id":"d88d0IpSlwP4"}},{"cell_type":"code","source":["# input dim\n","input_dim = X_train.shape[1]\n","\n","# train model\n","model, test_metrics = train_model(train_loader, val_loader, test_loader, input_dim, device)\n","\n","# model path\n","model_path = '/content/drive/MyDrive/semester 4/csci 1470: final project/' + 'energy_efficiency_model.pth'\n","\n","# save trained model\n","torch.save(model.state_dict(), model_path)"],"metadata":{"id":"z4COvXMClqTn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Ablation Studies**"],"metadata":{"id":"9hpofzUjj865"}},{"cell_type":"code","source":["# set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","ablations = ['av', 'fp', 'lst', 'sv']\n","for ablation in ablations:\n","  print(f\"ablation: {ablation}\")\n","  # get data and loaders\n","  data_loader_dict = get_loaders(ablation)\n","\n","  train_loader, val_loader, test_loader = data_loader_dict['loaders']\n","  X_train, y_train = data_loader_dict['data']\n","\n","  # input dim\n","  input_dim = X_train.shape[1]\n","\n","  # train model\n","  model, test_metrics = train_model(y_train, train_loader, val_loader, test_loader, input_dim, device)\n","\n","  # model path\n","  model_path = '/content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/' + ablation + '_energy_efficiency_model.pth'\n","  print(f\"path: {model_path}\")\n","\n","  # save trained model\n","  torch.save(model.state_dict(), model_path)\n","  print(f\"saved!\\n\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g5HVidS-YqqG","executionInfo":{"status":"ok","timestamp":1745947129967,"user_tz":240,"elapsed":372338,"user":{"displayName":"Athena Deng","userId":"09647360199161627987"}},"outputId":"2bb393b5-3693-4493-ce2f-7f6a4aa56b89"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n","ablation: av\n","Training data shape: (27922, 2048)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 2048)\n","Test data shape: (2756, 2048)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.6837 - Val Loss: 0.6777\n","Val Metrics: Precision=0.5861, Recall=0.5944, F1=0.5683\n","Epoch 2/30 - Train Loss: 0.6773 - Val Loss: 0.6711\n","Val Metrics: Precision=0.5882, Recall=0.5972, F1=0.5755\n","Epoch 3/30 - Train Loss: 0.6747 - Val Loss: 0.6782\n","Val Metrics: Precision=0.5943, Recall=0.6022, F1=0.5696\n","Epoch 4/30 - Train Loss: 0.6727 - Val Loss: 0.6578\n","Val Metrics: Precision=0.5871, Recall=0.5952, F1=0.5843\n","Epoch 5/30 - Train Loss: 0.6711 - Val Loss: 0.6566\n","Val Metrics: Precision=0.5867, Recall=0.5929, F1=0.5868\n","Epoch 6/30 - Train Loss: 0.6719 - Val Loss: 0.6680\n","Val Metrics: Precision=0.5875, Recall=0.5961, F1=0.5710\n","Epoch 7/30 - Train Loss: 0.6692 - Val Loss: 0.6825\n","Val Metrics: Precision=0.5902, Recall=0.5966, F1=0.5598\n","Epoch 8/30 - Train Loss: 0.6697 - Val Loss: 0.6764\n","Val Metrics: Precision=0.5890, Recall=0.5971, F1=0.5678\n","Epoch 9/30 - Train Loss: 0.6678 - Val Loss: 0.6643\n","Val Metrics: Precision=0.5930, Recall=0.6026, F1=0.5830\n","Epoch 10/30 - Train Loss: 0.6680 - Val Loss: 0.6702\n","Val Metrics: Precision=0.5971, Recall=0.6054, F1=0.5727\n","Epoch 11/30 - Train Loss: 0.6654 - Val Loss: 0.6562\n","Val Metrics: Precision=0.5886, Recall=0.5946, F1=0.5890\n","Epoch 12/30 - Train Loss: 0.6657 - Val Loss: 0.6556\n","Val Metrics: Precision=0.5881, Recall=0.5960, F1=0.5862\n","Epoch 13/30 - Train Loss: 0.6629 - Val Loss: 0.6570\n","Val Metrics: Precision=0.5861, Recall=0.5779, F1=0.5795\n","Epoch 14/30 - Train Loss: 0.6643 - Val Loss: 0.6633\n","Val Metrics: Precision=0.5812, Recall=0.5889, F1=0.5773\n","Epoch 15/30 - Train Loss: 0.6632 - Val Loss: 0.6623\n","Val Metrics: Precision=0.5830, Recall=0.5871, F1=0.5838\n","Epoch 16/30 - Train Loss: 0.6623 - Val Loss: 0.6746\n","Val Metrics: Precision=0.5925, Recall=0.5999, F1=0.5655\n","Epoch 17/30 - Train Loss: 0.6625 - Val Loss: 0.6788\n","Val Metrics: Precision=0.5955, Recall=0.6007, F1=0.5583\n","Epoch 18/30 - Train Loss: 0.6612 - Val Loss: 0.6566\n","Val Metrics: Precision=0.5808, Recall=0.5806, F1=0.5807\n","Epoch 19/30 - Train Loss: 0.6612 - Val Loss: 0.6685\n","Val Metrics: Precision=0.5774, Recall=0.5845, F1=0.5743\n","Epoch 20/30 - Train Loss: 0.6614 - Val Loss: 0.6922\n","Val Metrics: Precision=0.5936, Recall=0.5934, F1=0.5376\n","Epoch 21/30 - Train Loss: 0.6588 - Val Loss: 0.6571\n","Val Metrics: Precision=0.5907, Recall=0.6000, F1=0.5836\n","Epoch 22/30 - Train Loss: 0.6576 - Val Loss: 0.6794\n","Val Metrics: Precision=0.5885, Recall=0.5965, F1=0.5666\n","Epoch 23/30 - Train Loss: 0.6586 - Val Loss: 0.6556\n","Val Metrics: Precision=0.5805, Recall=0.5851, F1=0.5812\n","Epoch 24/30 - Train Loss: 0.6592 - Val Loss: 0.6567\n","Val Metrics: Precision=0.5856, Recall=0.5927, F1=0.5846\n","Epoch 25/30 - Train Loss: 0.6575 - Val Loss: 0.6758\n","Val Metrics: Precision=0.5888, Recall=0.5967, F1=0.5667\n","Epoch 26/30 - Train Loss: 0.6569 - Val Loss: 0.6682\n","Val Metrics: Precision=0.5846, Recall=0.5933, F1=0.5756\n","Epoch 27/30 - Train Loss: 0.6563 - Val Loss: 0.6579\n","Val Metrics: Precision=0.5920, Recall=0.6015, F1=0.5834\n","Epoch 28/30 - Train Loss: 0.6571 - Val Loss: 0.6866\n","Val Metrics: Precision=0.5862, Recall=0.5930, F1=0.5591\n","Epoch 29/30 - Train Loss: 0.6549 - Val Loss: 0.6530\n","Val Metrics: Precision=0.5894, Recall=0.5973, F1=0.5875\n","Epoch 30/30 - Train Loss: 0.6563 - Val Loss: 0.6694\n","Val Metrics: Precision=0.5849, Recall=0.5936, F1=0.5771\n","\n","Test Results:\n","Loss: 0.6152\n","Precision: 0.6128\n","Recall: 0.6321\n","F1 Score: 0.6189\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/av_energy_efficiency_model.pth\n","saved!\n","\n","\n","ablation: fp\n","Training data shape: (27922, 1)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 1)\n","Test data shape: (2756, 1)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 43.7894 - Val Loss: 5.5358\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 2/30 - Train Loss: 43.4473 - Val Loss: 5.2951\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 3/30 - Train Loss: 43.6915 - Val Loss: 5.5358\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 4/30 - Train Loss: 43.7001 - Val Loss: 5.5358\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 5/30 - Train Loss: 43.9111 - Val Loss: 5.5358\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 6/30 - Train Loss: 43.8702 - Val Loss: 5.2951\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 7/30 - Train Loss: 44.2388 - Val Loss: 5.5358\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 8/30 - Train Loss: 43.8195 - Val Loss: 5.5358\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 9/30 - Train Loss: 43.9212 - Val Loss: 5.5358\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 10/30 - Train Loss: 43.9481 - Val Loss: 5.5358\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 11/30 - Train Loss: 44.0252 - Val Loss: 5.5358\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 12/30 - Train Loss: 43.7281 - Val Loss: 5.5358\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 13/30 - Train Loss: 43.6756 - Val Loss: 5.2951\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 14/30 - Train Loss: 43.9524 - Val Loss: 5.5358\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 15/30 - Train Loss: 43.8337 - Val Loss: 5.5358\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 16/30 - Train Loss: 43.9734 - Val Loss: 5.5358\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 17/30 - Train Loss: 43.5027 - Val Loss: 5.5358\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 18/30 - Train Loss: 43.6663 - Val Loss: 5.2951\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 19/30 - Train Loss: 43.8763 - Val Loss: 5.2951\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 20/30 - Train Loss: 43.7827 - Val Loss: 5.2951\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 21/30 - Train Loss: 44.0689 - Val Loss: 5.5358\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 22/30 - Train Loss: 43.9259 - Val Loss: 5.5358\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 23/30 - Train Loss: 43.9723 - Val Loss: 5.5358\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 24/30 - Train Loss: 44.0353 - Val Loss: 5.5358\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 25/30 - Train Loss: 44.0679 - Val Loss: 5.2951\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 26/30 - Train Loss: 43.8994 - Val Loss: 5.2951\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 27/30 - Train Loss: 43.6806 - Val Loss: 5.2951\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 28/30 - Train Loss: 44.1446 - Val Loss: 5.2951\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 29/30 - Train Loss: 43.8085 - Val Loss: 5.2951\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 30/30 - Train Loss: 43.6147 - Val Loss: 5.2951\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","\n","Test Results:\n","Loss: 21.9158\n","Precision: 0.3904\n","Recall: 0.5000\n","F1 Score: 0.4385\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/fp_energy_efficiency_model.pth\n","saved!\n","\n","\n","ablation: lst\n","Training data shape: (27922, 3)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 3)\n","Test data shape: (2756, 3)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.6970 - Val Loss: 0.7125\n","Val Metrics: Precision=0.1736, Recall=0.5000, F1=0.2577\n","Epoch 2/30 - Train Loss: 0.6941 - Val Loss: 0.7027\n","Val Metrics: Precision=0.1736, Recall=0.5000, F1=0.2577\n","Epoch 3/30 - Train Loss: 0.6932 - Val Loss: 0.6985\n","Val Metrics: Precision=0.1736, Recall=0.5000, F1=0.2577\n","Epoch 4/30 - Train Loss: 0.6930 - Val Loss: 0.6962\n","Val Metrics: Precision=0.1736, Recall=0.5000, F1=0.2577\n","Epoch 5/30 - Train Loss: 0.6927 - Val Loss: 0.6951\n","Val Metrics: Precision=0.1736, Recall=0.5000, F1=0.2577\n","Epoch 6/30 - Train Loss: 0.6924 - Val Loss: 0.6942\n","Val Metrics: Precision=0.1736, Recall=0.5000, F1=0.2577\n","Epoch 7/30 - Train Loss: 0.6921 - Val Loss: 0.6932\n","Val Metrics: Precision=0.5241, Recall=0.5195, F1=0.4326\n","Epoch 8/30 - Train Loss: 0.6920 - Val Loss: 0.6929\n","Val Metrics: Precision=0.5317, Recall=0.5323, F1=0.4865\n","Epoch 9/30 - Train Loss: 0.6916 - Val Loss: 0.6924\n","Val Metrics: Precision=0.5522, Recall=0.5574, F1=0.5450\n","Epoch 10/30 - Train Loss: 0.6915 - Val Loss: 0.6914\n","Val Metrics: Precision=0.5731, Recall=0.5687, F1=0.5698\n","Epoch 11/30 - Train Loss: 0.6912 - Val Loss: 0.6917\n","Val Metrics: Precision=0.5609, Recall=0.5644, F1=0.5611\n","Epoch 12/30 - Train Loss: 0.6909 - Val Loss: 0.6914\n","Val Metrics: Precision=0.5696, Recall=0.5723, F1=0.5703\n","Epoch 13/30 - Train Loss: 0.6901 - Val Loss: 0.6907\n","Val Metrics: Precision=0.5724, Recall=0.5700, F1=0.5708\n","Epoch 14/30 - Train Loss: 0.6900 - Val Loss: 0.6898\n","Val Metrics: Precision=0.5786, Recall=0.5692, F1=0.5701\n","Epoch 15/30 - Train Loss: 0.6897 - Val Loss: 0.6880\n","Val Metrics: Precision=0.5894, Recall=0.5659, F1=0.5627\n","Epoch 16/30 - Train Loss: 0.6895 - Val Loss: 0.6882\n","Val Metrics: Precision=0.5858, Recall=0.5678, F1=0.5668\n","Epoch 17/30 - Train Loss: 0.6889 - Val Loss: 0.6892\n","Val Metrics: Precision=0.5764, Recall=0.5722, F1=0.5734\n","Epoch 18/30 - Train Loss: 0.6883 - Val Loss: 0.6873\n","Val Metrics: Precision=0.5826, Recall=0.5661, F1=0.5652\n","Epoch 19/30 - Train Loss: 0.6881 - Val Loss: 0.6860\n","Val Metrics: Precision=0.5892, Recall=0.5670, F1=0.5645\n","Epoch 20/30 - Train Loss: 0.6872 - Val Loss: 0.6855\n","Val Metrics: Precision=0.5850, Recall=0.5650, F1=0.5628\n","Epoch 21/30 - Train Loss: 0.6869 - Val Loss: 0.6850\n","Val Metrics: Precision=0.5842, Recall=0.5647, F1=0.5626\n","Epoch 22/30 - Train Loss: 0.6862 - Val Loss: 0.6838\n","Val Metrics: Precision=0.5934, Recall=0.5692, F1=0.5667\n","Epoch 23/30 - Train Loss: 0.6858 - Val Loss: 0.6834\n","Val Metrics: Precision=0.5892, Recall=0.5670, F1=0.5645\n","Epoch 24/30 - Train Loss: 0.6860 - Val Loss: 0.6828\n","Val Metrics: Precision=0.5893, Recall=0.5672, F1=0.5649\n","Epoch 25/30 - Train Loss: 0.6849 - Val Loss: 0.6813\n","Val Metrics: Precision=0.5931, Recall=0.5664, F1=0.5624\n","Epoch 26/30 - Train Loss: 0.6841 - Val Loss: 0.6809\n","Val Metrics: Precision=0.5915, Recall=0.5663, F1=0.5627\n","Epoch 27/30 - Train Loss: 0.6841 - Val Loss: 0.6800\n","Val Metrics: Precision=0.5956, Recall=0.5678, F1=0.5638\n","Epoch 28/30 - Train Loss: 0.6833 - Val Loss: 0.6798\n","Val Metrics: Precision=0.5960, Recall=0.5699, F1=0.5670\n","Epoch 29/30 - Train Loss: 0.6828 - Val Loss: 0.6793\n","Val Metrics: Precision=0.5974, Recall=0.5705, F1=0.5674\n","Epoch 30/30 - Train Loss: 0.6822 - Val Loss: 0.6785\n","Val Metrics: Precision=0.5981, Recall=0.5703, F1=0.5669\n","\n","Test Results:\n","Loss: 0.7338\n","Precision: 0.6104\n","Recall: 0.5046\n","F1 Score: 0.1900\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/lst_energy_efficiency_model.pth\n","saved!\n","\n","\n","ablation: sv\n","Training data shape: (27922, 2048)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 2048)\n","Test data shape: (2756, 2048)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.6899 - Val Loss: 0.6816\n","Val Metrics: Precision=0.5741, Recall=0.5816, F1=0.5606\n","Epoch 2/30 - Train Loss: 0.6827 - Val Loss: 0.6812\n","Val Metrics: Precision=0.5825, Recall=0.5876, F1=0.5483\n","Epoch 3/30 - Train Loss: 0.6803 - Val Loss: 0.6685\n","Val Metrics: Precision=0.5823, Recall=0.5908, F1=0.5723\n","Epoch 4/30 - Train Loss: 0.6780 - Val Loss: 0.6701\n","Val Metrics: Precision=0.5889, Recall=0.5965, F1=0.5650\n","Epoch 5/30 - Train Loss: 0.6771 - Val Loss: 0.6743\n","Val Metrics: Precision=0.5972, Recall=0.6011, F1=0.5546\n","Epoch 6/30 - Train Loss: 0.6754 - Val Loss: 0.6898\n","Val Metrics: Precision=0.5970, Recall=0.5779, F1=0.4849\n","Epoch 7/30 - Train Loss: 0.6729 - Val Loss: 0.6676\n","Val Metrics: Precision=0.5972, Recall=0.6034, F1=0.5632\n","Epoch 8/30 - Train Loss: 0.6724 - Val Loss: 0.6757\n","Val Metrics: Precision=0.6062, Recall=0.6050, F1=0.5461\n","Epoch 9/30 - Train Loss: 0.6705 - Val Loss: 0.6639\n","Val Metrics: Precision=0.5991, Recall=0.6065, F1=0.5699\n","Epoch 10/30 - Train Loss: 0.6712 - Val Loss: 0.6592\n","Val Metrics: Precision=0.5971, Recall=0.6062, F1=0.5771\n","Epoch 11/30 - Train Loss: 0.6701 - Val Loss: 0.6536\n","Val Metrics: Precision=0.5917, Recall=0.6011, F1=0.5807\n","Epoch 12/30 - Train Loss: 0.6689 - Val Loss: 0.6622\n","Val Metrics: Precision=0.6006, Recall=0.6080, F1=0.5710\n","Epoch 13/30 - Train Loss: 0.6685 - Val Loss: 0.6543\n","Val Metrics: Precision=0.5892, Recall=0.5982, F1=0.5742\n","Epoch 14/30 - Train Loss: 0.6679 - Val Loss: 0.6648\n","Val Metrics: Precision=0.6013, Recall=0.6071, F1=0.5650\n","Epoch 15/30 - Train Loss: 0.6660 - Val Loss: 0.6689\n","Val Metrics: Precision=0.6043, Recall=0.6066, F1=0.5553\n","Epoch 16/30 - Train Loss: 0.6683 - Val Loss: 0.6698\n","Val Metrics: Precision=0.6087, Recall=0.6087, F1=0.5519\n","Epoch 17/30 - Train Loss: 0.6675 - Val Loss: 0.6554\n","Val Metrics: Precision=0.5941, Recall=0.6025, F1=0.5718\n","Epoch 18/30 - Train Loss: 0.6663 - Val Loss: 0.6669\n","Val Metrics: Precision=0.6064, Recall=0.6087, F1=0.5567\n","Epoch 19/30 - Train Loss: 0.6656 - Val Loss: 0.6728\n","Val Metrics: Precision=0.6084, Recall=0.6058, F1=0.5439\n","Epoch 20/30 - Train Loss: 0.6665 - Val Loss: 0.6628\n","Val Metrics: Precision=0.6015, Recall=0.6055, F1=0.5585\n","Epoch 21/30 - Train Loss: 0.6653 - Val Loss: 0.6429\n","Val Metrics: Precision=0.5870, Recall=0.5959, F1=0.5802\n","Epoch 22/30 - Train Loss: 0.6657 - Val Loss: 0.6464\n","Val Metrics: Precision=0.5919, Recall=0.6014, F1=0.5808\n","Epoch 23/30 - Train Loss: 0.6650 - Val Loss: 0.6610\n","Val Metrics: Precision=0.5982, Recall=0.6032, F1=0.5596\n","Epoch 24/30 - Train Loss: 0.6624 - Val Loss: 0.6695\n","Val Metrics: Precision=0.6065, Recall=0.6060, F1=0.5483\n","Epoch 25/30 - Train Loss: 0.6648 - Val Loss: 0.6521\n","Val Metrics: Precision=0.5928, Recall=0.6015, F1=0.5730\n","Epoch 26/30 - Train Loss: 0.6633 - Val Loss: 0.6580\n","Val Metrics: Precision=0.6015, Recall=0.6070, F1=0.5637\n","Epoch 27/30 - Train Loss: 0.6614 - Val Loss: 0.6607\n","Val Metrics: Precision=0.6013, Recall=0.6056, F1=0.5592\n","Epoch 28/30 - Train Loss: 0.6634 - Val Loss: 0.6550\n","Val Metrics: Precision=0.5984, Recall=0.6052, F1=0.5668\n","Epoch 29/30 - Train Loss: 0.6628 - Val Loss: 0.6591\n","Val Metrics: Precision=0.6032, Recall=0.6077, F1=0.5616\n","Epoch 30/30 - Train Loss: 0.6632 - Val Loss: 0.6674\n","Val Metrics: Precision=0.6052, Recall=0.6053, F1=0.5490\n","\n","Test Results:\n","Loss: 0.5475\n","Precision: 0.6398\n","Recall: 0.6232\n","F1 Score: 0.6299\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/sv_energy_efficiency_model.pth\n","saved!\n","\n","\n"]}]},{"cell_type":"code","source":["# set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","ablations = ['av_fp', 'av_lst', 'av_sv', 'sv_fp', 'sv_lst', 'lst_fp']\n","for ablation in ablations:\n","  print(f\"ablation: {ablation}\")\n","  # get data and loaders\n","  data_loader_dict = get_loaders(ablation)\n","\n","  train_loader, val_loader, test_loader = data_loader_dict['loaders']\n","  X_train, y_train = data_loader_dict['data']\n","\n","  # input dim\n","  input_dim = X_train.shape[1]\n","\n","  # train model\n","  model, test_metrics = train_model(y_train, train_loader, val_loader, test_loader, input_dim, device)\n","\n","  # model path\n","  model_path = '/content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/' + ablation + '_energy_efficiency_model.pth'\n","  print(f\"path: {model_path}\")\n","\n","  # save trained model\n","  torch.save(model.state_dict(), model_path)\n","  print(f\"saved!\\n\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Nf-CqE5FOksq","executionInfo":{"status":"ok","timestamp":1745959590452,"user_tz":240,"elapsed":749471,"user":{"displayName":"Eric Zheng","userId":"09751706780638879012"}},"outputId":"7e5440e0-80b4-4d0a-ea65-0595628e188a"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n","ablation: av_fp\n","Training data shape: (27922, 2049)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 2049)\n","Test data shape: (2756, 2049)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.6892 - Val Loss: 0.7272\n","Val Metrics: Precision=0.6137, Recall=0.5112, F1=0.2896\n","Epoch 2/30 - Train Loss: 0.6818 - Val Loss: 0.7071\n","Val Metrics: Precision=0.6053, Recall=0.5600, F1=0.4263\n","Epoch 3/30 - Train Loss: 0.6802 - Val Loss: 0.6991\n","Val Metrics: Precision=0.6001, Recall=0.5751, F1=0.4727\n","Epoch 4/30 - Train Loss: 0.6773 - Val Loss: 0.6986\n","Val Metrics: Precision=0.5978, Recall=0.5774, F1=0.4826\n","Epoch 5/30 - Train Loss: 0.6770 - Val Loss: 0.6903\n","Val Metrics: Precision=0.5991, Recall=0.5918, F1=0.5208\n","Epoch 6/30 - Train Loss: 0.6761 - Val Loss: 0.6990\n","Val Metrics: Precision=0.5967, Recall=0.5683, F1=0.4585\n","Epoch 7/30 - Train Loss: 0.6745 - Val Loss: 0.6795\n","Val Metrics: Precision=0.5993, Recall=0.6046, F1=0.5616\n","Epoch 8/30 - Train Loss: 0.6753 - Val Loss: 0.6802\n","Val Metrics: Precision=0.5967, Recall=0.5946, F1=0.5343\n","Epoch 9/30 - Train Loss: 0.6731 - Val Loss: 0.6919\n","Val Metrics: Precision=0.5967, Recall=0.5809, F1=0.4940\n","Epoch 10/30 - Train Loss: 0.6721 - Val Loss: 0.6944\n","Val Metrics: Precision=0.6009, Recall=0.5756, F1=0.4730\n","Epoch 11/30 - Train Loss: 0.6714 - Val Loss: 0.6856\n","Val Metrics: Precision=0.5959, Recall=0.5876, F1=0.5148\n","Epoch 12/30 - Train Loss: 0.6713 - Val Loss: 0.6851\n","Val Metrics: Precision=0.5995, Recall=0.5955, F1=0.5312\n","Epoch 13/30 - Train Loss: 0.6699 - Val Loss: 0.6846\n","Val Metrics: Precision=0.5984, Recall=0.5922, F1=0.5236\n","Epoch 14/30 - Train Loss: 0.6682 - Val Loss: 0.6778\n","Val Metrics: Precision=0.5954, Recall=0.5985, F1=0.5505\n","Epoch 15/30 - Train Loss: 0.6681 - Val Loss: 0.6895\n","Val Metrics: Precision=0.5924, Recall=0.5705, F1=0.4709\n","Epoch 16/30 - Train Loss: 0.6675 - Val Loss: 0.6935\n","Val Metrics: Precision=0.5944, Recall=0.5822, F1=0.5015\n","Epoch 17/30 - Train Loss: 0.6669 - Val Loss: 0.6756\n","Val Metrics: Precision=0.5969, Recall=0.5939, F1=0.5317\n","Epoch 18/30 - Train Loss: 0.6676 - Val Loss: 0.6680\n","Val Metrics: Precision=0.5975, Recall=0.6050, F1=0.5693\n","Epoch 19/30 - Train Loss: 0.6659 - Val Loss: 0.6767\n","Val Metrics: Precision=0.5888, Recall=0.5880, F1=0.5312\n","Epoch 20/30 - Train Loss: 0.6652 - Val Loss: 0.6594\n","Val Metrics: Precision=0.5952, Recall=0.6047, F1=0.5799\n","Epoch 21/30 - Train Loss: 0.6658 - Val Loss: 0.6812\n","Val Metrics: Precision=0.5932, Recall=0.5869, F1=0.5178\n","Epoch 22/30 - Train Loss: 0.6634 - Val Loss: 0.6872\n","Val Metrics: Precision=0.5900, Recall=0.5808, F1=0.5053\n","Epoch 23/30 - Train Loss: 0.6638 - Val Loss: 0.6934\n","Val Metrics: Precision=0.5930, Recall=0.5803, F1=0.4984\n","Epoch 24/30 - Train Loss: 0.6631 - Val Loss: 0.6857\n","Val Metrics: Precision=0.5901, Recall=0.5805, F1=0.5041\n","Epoch 25/30 - Train Loss: 0.6608 - Val Loss: 0.6873\n","Val Metrics: Precision=0.5950, Recall=0.5763, F1=0.4835\n","Epoch 26/30 - Train Loss: 0.6626 - Val Loss: 0.6790\n","Val Metrics: Precision=0.5960, Recall=0.5854, F1=0.5079\n","Epoch 27/30 - Train Loss: 0.6626 - Val Loss: 0.6674\n","Val Metrics: Precision=0.5947, Recall=0.6000, F1=0.5582\n","Epoch 28/30 - Train Loss: 0.6615 - Val Loss: 0.6810\n","Val Metrics: Precision=0.5948, Recall=0.5834, F1=0.5044\n","Epoch 29/30 - Train Loss: 0.6613 - Val Loss: 0.6781\n","Val Metrics: Precision=0.5924, Recall=0.5884, F1=0.5240\n","Epoch 30/30 - Train Loss: 0.6602 - Val Loss: 0.6909\n","Val Metrics: Precision=0.6005, Recall=0.5792, F1=0.4834\n","\n","Test Results:\n","Loss: 0.6231\n","Precision: 0.5978\n","Recall: 0.6341\n","F1 Score: 0.5949\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/av_fp_energy_efficiency_model.pth\n","saved!\n","\n","\n","ablation: av_lst\n","Training data shape: (27922, 2051)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 2051)\n","Test data shape: (2756, 2051)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.6870 - Val Loss: 0.6758\n","Val Metrics: Precision=0.5862, Recall=0.5916, F1=0.5868\n","Epoch 2/30 - Train Loss: 0.6824 - Val Loss: 0.6773\n","Val Metrics: Precision=0.5900, Recall=0.5980, F1=0.5879\n","Epoch 3/30 - Train Loss: 0.6816 - Val Loss: 0.6712\n","Val Metrics: Precision=0.5834, Recall=0.5816, F1=0.5823\n","Epoch 4/30 - Train Loss: 0.6800 - Val Loss: 0.6801\n","Val Metrics: Precision=0.5861, Recall=0.5949, F1=0.5796\n","Epoch 5/30 - Train Loss: 0.6781 - Val Loss: 0.6702\n","Val Metrics: Precision=0.5848, Recall=0.5806, F1=0.5819\n","Epoch 6/30 - Train Loss: 0.6784 - Val Loss: 0.6738\n","Val Metrics: Precision=0.5903, Recall=0.5959, F1=0.5910\n","Epoch 7/30 - Train Loss: 0.6772 - Val Loss: 0.6728\n","Val Metrics: Precision=0.5911, Recall=0.5961, F1=0.5920\n","Epoch 8/30 - Train Loss: 0.6766 - Val Loss: 0.6687\n","Val Metrics: Precision=0.5840, Recall=0.5808, F1=0.5820\n","Epoch 9/30 - Train Loss: 0.6762 - Val Loss: 0.6722\n","Val Metrics: Precision=0.5890, Recall=0.5949, F1=0.5895\n","Epoch 10/30 - Train Loss: 0.6768 - Val Loss: 0.6714\n","Val Metrics: Precision=0.5895, Recall=0.5949, F1=0.5902\n","Epoch 11/30 - Train Loss: 0.6759 - Val Loss: 0.6774\n","Val Metrics: Precision=0.5909, Recall=0.5998, F1=0.5865\n","Epoch 12/30 - Train Loss: 0.6752 - Val Loss: 0.6703\n","Val Metrics: Precision=0.5904, Recall=0.5946, F1=0.5914\n","Epoch 13/30 - Train Loss: 0.6739 - Val Loss: 0.6680\n","Val Metrics: Precision=0.5861, Recall=0.5879, F1=0.5869\n","Epoch 14/30 - Train Loss: 0.6738 - Val Loss: 0.6700\n","Val Metrics: Precision=0.5886, Recall=0.5927, F1=0.5896\n","Epoch 15/30 - Train Loss: 0.6726 - Val Loss: 0.6687\n","Val Metrics: Precision=0.5891, Recall=0.5917, F1=0.5901\n","Epoch 16/30 - Train Loss: 0.6725 - Val Loss: 0.6657\n","Val Metrics: Precision=0.5858, Recall=0.5843, F1=0.5850\n","Epoch 17/30 - Train Loss: 0.6730 - Val Loss: 0.6617\n","Val Metrics: Precision=0.5918, Recall=0.5787, F1=0.5799\n","Epoch 18/30 - Train Loss: 0.6708 - Val Loss: 0.6636\n","Val Metrics: Precision=0.5884, Recall=0.5833, F1=0.5848\n","Epoch 19/30 - Train Loss: 0.6717 - Val Loss: 0.6810\n","Val Metrics: Precision=0.5895, Recall=0.5987, F1=0.5783\n","Epoch 20/30 - Train Loss: 0.6704 - Val Loss: 0.6785\n","Val Metrics: Precision=0.5857, Recall=0.5944, F1=0.5794\n","Epoch 21/30 - Train Loss: 0.6706 - Val Loss: 0.6675\n","Val Metrics: Precision=0.5886, Recall=0.5905, F1=0.5894\n","Epoch 22/30 - Train Loss: 0.6704 - Val Loss: 0.6977\n","Val Metrics: Precision=0.5955, Recall=0.6007, F1=0.5583\n","Epoch 23/30 - Train Loss: 0.6679 - Val Loss: 0.6733\n","Val Metrics: Precision=0.5934, Recall=0.6011, F1=0.5927\n","Epoch 24/30 - Train Loss: 0.6697 - Val Loss: 0.6691\n","Val Metrics: Precision=0.5869, Recall=0.5913, F1=0.5878\n","Epoch 25/30 - Train Loss: 0.6690 - Val Loss: 0.6791\n","Val Metrics: Precision=0.5868, Recall=0.5956, F1=0.5801\n","Epoch 26/30 - Train Loss: 0.6686 - Val Loss: 0.6607\n","Val Metrics: Precision=0.5888, Recall=0.5785, F1=0.5800\n","Epoch 27/30 - Train Loss: 0.6682 - Val Loss: 0.6606\n","Val Metrics: Precision=0.5844, Recall=0.5735, F1=0.5746\n","Epoch 28/30 - Train Loss: 0.6676 - Val Loss: 0.6676\n","Val Metrics: Precision=0.5871, Recall=0.5890, F1=0.5878\n","Epoch 29/30 - Train Loss: 0.6693 - Val Loss: 0.6871\n","Val Metrics: Precision=0.5921, Recall=0.6012, F1=0.5762\n","Epoch 30/30 - Train Loss: 0.6674 - Val Loss: 0.6733\n","Val Metrics: Precision=0.5894, Recall=0.5963, F1=0.5891\n","\n","Test Results:\n","Loss: 0.6368\n","Precision: 0.6129\n","Recall: 0.6231\n","F1 Score: 0.6170\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/av_lst_energy_efficiency_model.pth\n","saved!\n","\n","\n","ablation: av_sv\n","Training data shape: (27922, 4096)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 4096)\n","Test data shape: (2756, 4096)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.6844 - Val Loss: 0.6605\n","Val Metrics: Precision=0.5993, Recall=0.6065, F1=0.5997\n","Epoch 2/30 - Train Loss: 0.6782 - Val Loss: 0.6608\n","Val Metrics: Precision=0.6040, Recall=0.6145, F1=0.5896\n","Epoch 3/30 - Train Loss: 0.6749 - Val Loss: 0.6671\n","Val Metrics: Precision=0.6100, Recall=0.6155, F1=0.5707\n","Epoch 4/30 - Train Loss: 0.6728 - Val Loss: 0.6675\n","Val Metrics: Precision=0.6138, Recall=0.6173, F1=0.5669\n","Epoch 5/30 - Train Loss: 0.6719 - Val Loss: 0.6636\n","Val Metrics: Precision=0.6162, Recall=0.6224, F1=0.5777\n","Epoch 6/30 - Train Loss: 0.6711 - Val Loss: 0.6421\n","Val Metrics: Precision=0.5916, Recall=0.6004, F1=0.5877\n","Epoch 7/30 - Train Loss: 0.6695 - Val Loss: 0.6398\n","Val Metrics: Precision=0.5950, Recall=0.6042, F1=0.5909\n","Epoch 8/30 - Train Loss: 0.6685 - Val Loss: 0.6543\n","Val Metrics: Precision=0.6132, Recall=0.6221, F1=0.5856\n","Epoch 9/30 - Train Loss: 0.6671 - Val Loss: 0.6660\n","Val Metrics: Precision=0.6216, Recall=0.6206, F1=0.5608\n","Epoch 10/30 - Train Loss: 0.6669 - Val Loss: 0.6413\n","Val Metrics: Precision=0.5982, Recall=0.6083, F1=0.5877\n","Epoch 11/30 - Train Loss: 0.6681 - Val Loss: 0.6659\n","Val Metrics: Precision=0.6207, Recall=0.6201, F1=0.5611\n","Epoch 12/30 - Train Loss: 0.6648 - Val Loss: 0.6566\n","Val Metrics: Precision=0.6144, Recall=0.6218, F1=0.5807\n","Epoch 13/30 - Train Loss: 0.6649 - Val Loss: 0.6441\n","Val Metrics: Precision=0.6035, Recall=0.6134, F1=0.5852\n","Epoch 14/30 - Train Loss: 0.6638 - Val Loss: 0.6417\n","Val Metrics: Precision=0.6033, Recall=0.6134, F1=0.5867\n","Epoch 15/30 - Train Loss: 0.6616 - Val Loss: 0.6547\n","Val Metrics: Precision=0.6174, Recall=0.6238, F1=0.5794\n","Epoch 16/30 - Train Loss: 0.6630 - Val Loss: 0.6723\n","Val Metrics: Precision=0.6225, Recall=0.6120, F1=0.5370\n","Epoch 17/30 - Train Loss: 0.6614 - Val Loss: 0.6436\n","Val Metrics: Precision=0.6079, Recall=0.6180, F1=0.5879\n","Epoch 18/30 - Train Loss: 0.6630 - Val Loss: 0.6695\n","Val Metrics: Precision=0.6200, Recall=0.6121, F1=0.5410\n","Epoch 19/30 - Train Loss: 0.6599 - Val Loss: 0.6368\n","Val Metrics: Precision=0.6006, Recall=0.6108, F1=0.5882\n","Epoch 20/30 - Train Loss: 0.6609 - Val Loss: 0.6452\n","Val Metrics: Precision=0.6058, Recall=0.6149, F1=0.5819\n","Epoch 21/30 - Train Loss: 0.6596 - Val Loss: 0.6648\n","Val Metrics: Precision=0.6171, Recall=0.6129, F1=0.5480\n","Epoch 22/30 - Train Loss: 0.6590 - Val Loss: 0.6431\n","Val Metrics: Precision=0.6095, Recall=0.6187, F1=0.5847\n","Epoch 23/30 - Train Loss: 0.6593 - Val Loss: 0.6690\n","Val Metrics: Precision=0.6240, Recall=0.6155, F1=0.5435\n","Epoch 24/30 - Train Loss: 0.6578 - Val Loss: 0.6324\n","Val Metrics: Precision=0.6033, Recall=0.6139, F1=0.5938\n","Epoch 25/30 - Train Loss: 0.6576 - Val Loss: 0.6354\n","Val Metrics: Precision=0.6076, Recall=0.6185, F1=0.5940\n","Epoch 26/30 - Train Loss: 0.6556 - Val Loss: 0.6643\n","Val Metrics: Precision=0.6164, Recall=0.6109, F1=0.5436\n","Epoch 27/30 - Train Loss: 0.6575 - Val Loss: 0.6518\n","Val Metrics: Precision=0.6077, Recall=0.6121, F1=0.5649\n","Epoch 28/30 - Train Loss: 0.6566 - Val Loss: 0.6337\n","Val Metrics: Precision=0.6107, Recall=0.6219, F1=0.5967\n","Epoch 29/30 - Train Loss: 0.6558 - Val Loss: 0.6477\n","Val Metrics: Precision=0.6058, Recall=0.6114, F1=0.5677\n","Epoch 30/30 - Train Loss: 0.6551 - Val Loss: 0.6521\n","Val Metrics: Precision=0.6088, Recall=0.6124, F1=0.5633\n","\n","Test Results:\n","Loss: 0.5290\n","Precision: 0.6645\n","Recall: 0.6676\n","F1 Score: 0.6660\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/av_sv_energy_efficiency_model.pth\n","saved!\n","\n","\n","ablation: sv_fp\n","Training data shape: (27922, 2049)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 2049)\n","Test data shape: (2756, 2049)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.6953 - Val Loss: 0.7213\n","Val Metrics: Precision=0.1736, Recall=0.5000, F1=0.2577\n","Epoch 2/30 - Train Loss: 0.6909 - Val Loss: 0.7102\n","Val Metrics: Precision=0.5762, Recall=0.5110, F1=0.2987\n","Epoch 3/30 - Train Loss: 0.6874 - Val Loss: 0.7006\n","Val Metrics: Precision=0.5904, Recall=0.5575, F1=0.4360\n","Epoch 4/30 - Train Loss: 0.6860 - Val Loss: 0.6998\n","Val Metrics: Precision=0.5891, Recall=0.5570, F1=0.4363\n","Epoch 5/30 - Train Loss: 0.6841 - Val Loss: 0.6896\n","Val Metrics: Precision=0.5968, Recall=0.5894, F1=0.5183\n","Epoch 6/30 - Train Loss: 0.6812 - Val Loss: 0.6870\n","Val Metrics: Precision=0.5944, Recall=0.5896, F1=0.5235\n","Epoch 7/30 - Train Loss: 0.6815 - Val Loss: 0.6958\n","Val Metrics: Precision=0.5927, Recall=0.5597, F1=0.4395\n","Epoch 8/30 - Train Loss: 0.6792 - Val Loss: 0.6830\n","Val Metrics: Precision=0.5968, Recall=0.5942, F1=0.5328\n","Epoch 9/30 - Train Loss: 0.6794 - Val Loss: 0.6905\n","Val Metrics: Precision=0.5976, Recall=0.5712, F1=0.4653\n","Epoch 10/30 - Train Loss: 0.6780 - Val Loss: 0.6874\n","Val Metrics: Precision=0.6032, Recall=0.5822, F1=0.4879\n","Epoch 11/30 - Train Loss: 0.6761 - Val Loss: 0.6739\n","Val Metrics: Precision=0.6004, Recall=0.6064, F1=0.5649\n","Epoch 12/30 - Train Loss: 0.6759 - Val Loss: 0.6841\n","Val Metrics: Precision=0.6047, Recall=0.5869, F1=0.4980\n","Epoch 13/30 - Train Loss: 0.6760 - Val Loss: 0.6852\n","Val Metrics: Precision=0.6030, Recall=0.5817, F1=0.4866\n","Epoch 14/30 - Train Loss: 0.6744 - Val Loss: 0.6728\n","Val Metrics: Precision=0.5914, Recall=0.5950, F1=0.5489\n","Epoch 15/30 - Train Loss: 0.6744 - Val Loss: 0.6759\n","Val Metrics: Precision=0.6054, Recall=0.6026, F1=0.5407\n","Epoch 16/30 - Train Loss: 0.6741 - Val Loss: 0.6800\n","Val Metrics: Precision=0.6071, Recall=0.5926, F1=0.5099\n","Epoch 17/30 - Train Loss: 0.6728 - Val Loss: 0.6765\n","Val Metrics: Precision=0.6073, Recall=0.6000, F1=0.5296\n","Epoch 18/30 - Train Loss: 0.6720 - Val Loss: 0.6656\n","Val Metrics: Precision=0.5962, Recall=0.6042, F1=0.5708\n","Epoch 19/30 - Train Loss: 0.6712 - Val Loss: 0.6708\n","Val Metrics: Precision=0.5993, Recall=0.6009, F1=0.5486\n","Epoch 20/30 - Train Loss: 0.6712 - Val Loss: 0.6696\n","Val Metrics: Precision=0.6029, Recall=0.6040, F1=0.5501\n","Epoch 21/30 - Train Loss: 0.6707 - Val Loss: 0.6709\n","Val Metrics: Precision=0.6093, Recall=0.6085, F1=0.5501\n","Epoch 22/30 - Train Loss: 0.6719 - Val Loss: 0.6703\n","Val Metrics: Precision=0.6063, Recall=0.6040, F1=0.5429\n","Epoch 23/30 - Train Loss: 0.6708 - Val Loss: 0.6681\n","Val Metrics: Precision=0.6032, Recall=0.6049, F1=0.5522\n","Epoch 24/30 - Train Loss: 0.6704 - Val Loss: 0.6594\n","Val Metrics: Precision=0.5964, Recall=0.6058, F1=0.5795\n","Epoch 25/30 - Train Loss: 0.6699 - Val Loss: 0.6639\n","Val Metrics: Precision=0.6021, Recall=0.6091, F1=0.5701\n","Epoch 26/30 - Train Loss: 0.6680 - Val Loss: 0.6566\n","Val Metrics: Precision=0.5950, Recall=0.6045, F1=0.5805\n","Epoch 27/30 - Train Loss: 0.6689 - Val Loss: 0.6543\n","Val Metrics: Precision=0.5955, Recall=0.6053, F1=0.5864\n","Epoch 28/30 - Train Loss: 0.6673 - Val Loss: 0.6682\n","Val Metrics: Precision=0.6073, Recall=0.6087, F1=0.5550\n","Epoch 29/30 - Train Loss: 0.6684 - Val Loss: 0.6651\n","Val Metrics: Precision=0.6056, Recall=0.6086, F1=0.5584\n","Epoch 30/30 - Train Loss: 0.6674 - Val Loss: 0.6652\n","Val Metrics: Precision=0.6038, Recall=0.6057, F1=0.5536\n","\n","Test Results:\n","Loss: 0.5743\n","Precision: 0.6536\n","Recall: 0.6204\n","F1 Score: 0.6313\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/sv_fp_energy_efficiency_model.pth\n","saved!\n","\n","\n","ablation: sv_lst\n","Training data shape: (27922, 2051)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 2051)\n","Test data shape: (2756, 2051)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.6915 - Val Loss: 0.6908\n","Val Metrics: Precision=0.5712, Recall=0.5767, F1=0.5432\n","Epoch 2/30 - Train Loss: 0.6891 - Val Loss: 0.6816\n","Val Metrics: Precision=0.5752, Recall=0.5688, F1=0.5700\n","Epoch 3/30 - Train Loss: 0.6862 - Val Loss: 0.6893\n","Val Metrics: Precision=0.5775, Recall=0.5846, F1=0.5571\n","Epoch 4/30 - Train Loss: 0.6862 - Val Loss: 0.6855\n","Val Metrics: Precision=0.5863, Recall=0.5942, F1=0.5836\n","Epoch 5/30 - Train Loss: 0.6848 - Val Loss: 0.6864\n","Val Metrics: Precision=0.5885, Recall=0.5971, F1=0.5840\n","Epoch 6/30 - Train Loss: 0.6824 - Val Loss: 0.6811\n","Val Metrics: Precision=0.5828, Recall=0.5855, F1=0.5837\n","Epoch 7/30 - Train Loss: 0.6810 - Val Loss: 0.6827\n","Val Metrics: Precision=0.5899, Recall=0.5965, F1=0.5899\n","Epoch 8/30 - Train Loss: 0.6795 - Val Loss: 0.6746\n","Val Metrics: Precision=0.5942, Recall=0.5808, F1=0.5822\n","Epoch 9/30 - Train Loss: 0.6805 - Val Loss: 0.6769\n","Val Metrics: Precision=0.5829, Recall=0.5808, F1=0.5817\n","Epoch 10/30 - Train Loss: 0.6795 - Val Loss: 0.6799\n","Val Metrics: Precision=0.5915, Recall=0.5976, F1=0.5921\n","Epoch 11/30 - Train Loss: 0.6778 - Val Loss: 0.6752\n","Val Metrics: Precision=0.5904, Recall=0.5911, F1=0.5907\n","Epoch 12/30 - Train Loss: 0.6778 - Val Loss: 0.6872\n","Val Metrics: Precision=0.5909, Recall=0.6001, F1=0.5765\n","Epoch 13/30 - Train Loss: 0.6769 - Val Loss: 0.6755\n","Val Metrics: Precision=0.5948, Recall=0.5966, F1=0.5955\n","Epoch 14/30 - Train Loss: 0.6775 - Val Loss: 0.6708\n","Val Metrics: Precision=0.5957, Recall=0.5859, F1=0.5878\n","Epoch 15/30 - Train Loss: 0.6763 - Val Loss: 0.6712\n","Val Metrics: Precision=0.5957, Recall=0.5893, F1=0.5911\n","Epoch 16/30 - Train Loss: 0.6765 - Val Loss: 0.6731\n","Val Metrics: Precision=0.5965, Recall=0.5968, F1=0.5967\n","Epoch 17/30 - Train Loss: 0.6760 - Val Loss: 0.6850\n","Val Metrics: Precision=0.5930, Recall=0.6026, F1=0.5845\n","Epoch 18/30 - Train Loss: 0.6750 - Val Loss: 0.6857\n","Val Metrics: Precision=0.5917, Recall=0.6011, F1=0.5809\n","Epoch 19/30 - Train Loss: 0.6736 - Val Loss: 0.6705\n","Val Metrics: Precision=0.5950, Recall=0.5898, F1=0.5915\n","Epoch 20/30 - Train Loss: 0.6731 - Val Loss: 0.6668\n","Val Metrics: Precision=0.5980, Recall=0.5841, F1=0.5858\n","Epoch 21/30 - Train Loss: 0.6753 - Val Loss: 0.6680\n","Val Metrics: Precision=0.6016, Recall=0.5923, F1=0.5945\n","Epoch 22/30 - Train Loss: 0.6733 - Val Loss: 0.6695\n","Val Metrics: Precision=0.6007, Recall=0.5975, F1=0.5987\n","Epoch 23/30 - Train Loss: 0.6740 - Val Loss: 0.6699\n","Val Metrics: Precision=0.6001, Recall=0.5978, F1=0.5988\n","Epoch 24/30 - Train Loss: 0.6732 - Val Loss: 0.6667\n","Val Metrics: Precision=0.5991, Recall=0.5897, F1=0.5918\n","Epoch 25/30 - Train Loss: 0.6738 - Val Loss: 0.6677\n","Val Metrics: Precision=0.6026, Recall=0.5949, F1=0.5970\n","Epoch 26/30 - Train Loss: 0.6722 - Val Loss: 0.6845\n","Val Metrics: Precision=0.5952, Recall=0.6050, F1=0.5859\n","Epoch 27/30 - Train Loss: 0.6696 - Val Loss: 0.6711\n","Val Metrics: Precision=0.5970, Recall=0.5979, F1=0.5974\n","Epoch 28/30 - Train Loss: 0.6705 - Val Loss: 0.6849\n","Val Metrics: Precision=0.5933, Recall=0.6030, F1=0.5840\n","Epoch 29/30 - Train Loss: 0.6730 - Val Loss: 0.6663\n","Val Metrics: Precision=0.6010, Recall=0.5936, F1=0.5956\n","Epoch 30/30 - Train Loss: 0.6694 - Val Loss: 0.6701\n","Val Metrics: Precision=0.6018, Recall=0.6029, F1=0.6023\n","\n","Test Results:\n","Loss: 0.6281\n","Precision: 0.6698\n","Recall: 0.5789\n","F1 Score: 0.5873\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/sv_lst_energy_efficiency_model.pth\n","saved!\n","\n","\n","ablation: lst_fp\n","Training data shape: (27922, 4)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 4)\n","Test data shape: (2756, 4)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 26.1424 - Val Loss: 1.8254\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 2/30 - Train Loss: 26.0506 - Val Loss: 1.8223\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 3/30 - Train Loss: 25.2900 - Val Loss: 1.8215\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 4/30 - Train Loss: 25.3929 - Val Loss: 1.8290\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 5/30 - Train Loss: 25.6889 - Val Loss: 1.8167\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 6/30 - Train Loss: 25.2510 - Val Loss: 1.8246\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 7/30 - Train Loss: 25.0616 - Val Loss: 1.8315\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 8/30 - Train Loss: 25.4618 - Val Loss: 1.8281\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 9/30 - Train Loss: 25.3156 - Val Loss: 1.8314\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 10/30 - Train Loss: 25.6137 - Val Loss: 1.8392\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 11/30 - Train Loss: 25.5909 - Val Loss: 1.8380\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 12/30 - Train Loss: 25.8351 - Val Loss: 1.8358\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 13/30 - Train Loss: 25.2345 - Val Loss: 1.8405\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 14/30 - Train Loss: 25.5391 - Val Loss: 1.8415\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 15/30 - Train Loss: 25.0510 - Val Loss: 1.8267\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 16/30 - Train Loss: 25.6593 - Val Loss: 1.8341\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 17/30 - Train Loss: 25.5564 - Val Loss: 1.8430\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 18/30 - Train Loss: 25.7433 - Val Loss: 1.8311\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 19/30 - Train Loss: 25.6832 - Val Loss: 1.8401\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 20/30 - Train Loss: 25.6282 - Val Loss: 1.8282\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 21/30 - Train Loss: 25.8044 - Val Loss: 1.8381\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 22/30 - Train Loss: 25.5646 - Val Loss: 1.8372\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 23/30 - Train Loss: 25.2926 - Val Loss: 1.8370\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 24/30 - Train Loss: 25.5394 - Val Loss: 1.8423\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 25/30 - Train Loss: 24.8427 - Val Loss: 1.8378\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 26/30 - Train Loss: 25.4042 - Val Loss: 1.8379\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 27/30 - Train Loss: 25.2365 - Val Loss: 1.8381\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 28/30 - Train Loss: 25.3109 - Val Loss: 1.8365\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 29/30 - Train Loss: 25.6906 - Val Loss: 1.8346\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 30/30 - Train Loss: 25.5207 - Val Loss: 1.8379\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","\n","Test Results:\n","Loss: 3.1889\n","Precision: 0.3904\n","Recall: 0.5000\n","F1 Score: 0.4385\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/lst_fp_energy_efficiency_model.pth\n","saved!\n","\n","\n"]}]},{"cell_type":"code","source":["# set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","ablations = ['av_lst_fp', 'av_sv_lst', 'av_sv_fp', 'sv_lst_fp']\n","for ablation in ablations:\n","  print(f\"ablation: {ablation}\")\n","  # get data and loaders\n","  data_loader_dict = get_loaders(ablation)\n","\n","  train_loader, val_loader, test_loader = data_loader_dict['loaders']\n","  X_train, y_train = data_loader_dict['data']\n","\n","  # input dim\n","  input_dim = X_train.shape[1]\n","\n","  # train model\n","  model, test_metrics = train_model(y_train, train_loader, val_loader, test_loader, input_dim, device)\n","\n","  # model path\n","  model_path = '/content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/' + ablation + '_energy_efficiency_model.pth'\n","  print(f\"path: {model_path}\")\n","\n","  # save trained model\n","  torch.save(model.state_dict(), model_path)\n","  print(f\"saved!\\n\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JOkzPDRTVT6S","executionInfo":{"status":"ok","timestamp":1745960832062,"user_tz":240,"elapsed":566963,"user":{"displayName":"Eric Zheng","userId":"09751706780638879012"}},"outputId":"fef91aa7-5115-4808-f5f8-aaa6d2f01f8b"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n","ablation: av_lst_fp\n","Training data shape: (27922, 2052)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 2052)\n","Test data shape: (2756, 2052)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.6962 - Val Loss: 0.6797\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 2/30 - Train Loss: 0.6939 - Val Loss: 0.6833\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 3/30 - Train Loss: 0.6903 - Val Loss: 0.6862\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 4/30 - Train Loss: 0.6859 - Val Loss: 0.6875\n","Val Metrics: Precision=0.5940, Recall=0.5584, F1=0.4342\n","Epoch 5/30 - Train Loss: 0.6855 - Val Loss: 0.6910\n","Val Metrics: Precision=0.5985, Recall=0.5546, F1=0.4184\n","Epoch 6/30 - Train Loss: 0.6831 - Val Loss: 0.6822\n","Val Metrics: Precision=0.6042, Recall=0.5965, F1=0.5251\n","Epoch 7/30 - Train Loss: 0.6813 - Val Loss: 0.6891\n","Val Metrics: Precision=0.5968, Recall=0.5680, F1=0.4575\n","Epoch 8/30 - Train Loss: 0.6786 - Val Loss: 0.6892\n","Val Metrics: Precision=0.5984, Recall=0.5750, F1=0.4748\n","Epoch 9/30 - Train Loss: 0.6783 - Val Loss: 0.6856\n","Val Metrics: Precision=0.6002, Recall=0.5847, F1=0.4991\n","Epoch 10/30 - Train Loss: 0.6787 - Val Loss: 0.6909\n","Val Metrics: Precision=0.6061, Recall=0.5778, F1=0.4721\n","Epoch 11/30 - Train Loss: 0.6756 - Val Loss: 0.7032\n","Val Metrics: Precision=0.5958, Recall=0.5440, F1=0.3912\n","Epoch 12/30 - Train Loss: 0.6769 - Val Loss: 0.6854\n","Val Metrics: Precision=0.5989, Recall=0.5849, F1=0.5018\n","Epoch 13/30 - Train Loss: 0.6754 - Val Loss: 0.6913\n","Val Metrics: Precision=0.6023, Recall=0.5787, F1=0.4796\n","Epoch 14/30 - Train Loss: 0.6768 - Val Loss: 0.6957\n","Val Metrics: Precision=0.6028, Recall=0.5719, F1=0.4606\n","Epoch 15/30 - Train Loss: 0.6758 - Val Loss: 0.6866\n","Val Metrics: Precision=0.6042, Recall=0.5882, F1=0.5023\n","Epoch 16/30 - Train Loss: 0.6739 - Val Loss: 0.6875\n","Val Metrics: Precision=0.5991, Recall=0.5840, F1=0.4988\n","Epoch 17/30 - Train Loss: 0.6742 - Val Loss: 0.6656\n","Val Metrics: Precision=0.6007, Recall=0.6083, F1=0.5717\n","Epoch 18/30 - Train Loss: 0.6730 - Val Loss: 0.6826\n","Val Metrics: Precision=0.5907, Recall=0.5823, F1=0.5085\n","Epoch 19/30 - Train Loss: 0.6727 - Val Loss: 0.6829\n","Val Metrics: Precision=0.5931, Recall=0.5837, F1=0.5082\n","Epoch 20/30 - Train Loss: 0.6722 - Val Loss: 0.6912\n","Val Metrics: Precision=0.5980, Recall=0.5783, F1=0.4847\n","Epoch 21/30 - Train Loss: 0.6725 - Val Loss: 0.6891\n","Val Metrics: Precision=0.5948, Recall=0.5781, F1=0.4892\n","Epoch 22/30 - Train Loss: 0.6731 - Val Loss: 0.6745\n","Val Metrics: Precision=0.5989, Recall=0.5983, F1=0.5412\n","Epoch 23/30 - Train Loss: 0.6707 - Val Loss: 0.6730\n","Val Metrics: Precision=0.5998, Recall=0.6001, F1=0.5447\n","Epoch 24/30 - Train Loss: 0.6712 - Val Loss: 0.6753\n","Val Metrics: Precision=0.5965, Recall=0.5943, F1=0.5339\n","Epoch 25/30 - Train Loss: 0.6731 - Val Loss: 0.6857\n","Val Metrics: Precision=0.5942, Recall=0.5801, F1=0.4957\n","Epoch 26/30 - Train Loss: 0.6722 - Val Loss: 0.6835\n","Val Metrics: Precision=0.5957, Recall=0.5826, F1=0.5005\n","Epoch 27/30 - Train Loss: 0.6715 - Val Loss: 0.6820\n","Val Metrics: Precision=0.5916, Recall=0.5821, F1=0.5064\n","Epoch 28/30 - Train Loss: 0.6685 - Val Loss: 0.6773\n","Val Metrics: Precision=0.5965, Recall=0.5923, F1=0.5276\n","Epoch 29/30 - Train Loss: 0.6700 - Val Loss: 0.6752\n","Val Metrics: Precision=0.5924, Recall=0.5891, F1=0.5263\n","Epoch 30/30 - Train Loss: 0.6687 - Val Loss: 0.6939\n","Val Metrics: Precision=0.6039, Recall=0.5765, F1=0.4716\n","\n","Test Results:\n","Loss: 0.6204\n","Precision: 0.6047\n","Recall: 0.6438\n","F1 Score: 0.6024\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/av_lst_fp_energy_efficiency_model.pth\n","saved!\n","\n","\n","ablation: av_sv_lst\n","Training data shape: (27922, 4099)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 4099)\n","Test data shape: (2756, 4099)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.6848 - Val Loss: 0.6753\n","Val Metrics: Precision=0.5970, Recall=0.6048, F1=0.5965\n","Epoch 2/30 - Train Loss: 0.6787 - Val Loss: 0.6743\n","Val Metrics: Precision=0.5948, Recall=0.6034, F1=0.5926\n","Epoch 3/30 - Train Loss: 0.6776 - Val Loss: 0.6761\n","Val Metrics: Precision=0.6000, Recall=0.6097, F1=0.5960\n","Epoch 4/30 - Train Loss: 0.6741 - Val Loss: 0.6712\n","Val Metrics: Precision=0.5978, Recall=0.6045, F1=0.5984\n","Epoch 5/30 - Train Loss: 0.6736 - Val Loss: 0.6780\n","Val Metrics: Precision=0.6010, Recall=0.6112, F1=0.5951\n","Epoch 6/30 - Train Loss: 0.6721 - Val Loss: 0.6630\n","Val Metrics: Precision=0.5988, Recall=0.5965, F1=0.5975\n","Epoch 7/30 - Train Loss: 0.6705 - Val Loss: 0.6638\n","Val Metrics: Precision=0.6019, Recall=0.6003, F1=0.6010\n","Epoch 8/30 - Train Loss: 0.6691 - Val Loss: 0.6719\n","Val Metrics: Precision=0.6052, Recall=0.6149, F1=0.6030\n","Epoch 9/30 - Train Loss: 0.6669 - Val Loss: 0.6691\n","Val Metrics: Precision=0.6012, Recall=0.6080, F1=0.6019\n","Epoch 10/30 - Train Loss: 0.6680 - Val Loss: 0.6623\n","Val Metrics: Precision=0.6020, Recall=0.6023, F1=0.6022\n","Epoch 11/30 - Train Loss: 0.6667 - Val Loss: 0.6624\n","Val Metrics: Precision=0.6080, Recall=0.6094, F1=0.6086\n","Epoch 12/30 - Train Loss: 0.6658 - Val Loss: 0.6766\n","Val Metrics: Precision=0.6039, Recall=0.6144, F1=0.5985\n","Epoch 13/30 - Train Loss: 0.6644 - Val Loss: 0.6517\n","Val Metrics: Precision=0.6004, Recall=0.5567, F1=0.5430\n","Epoch 14/30 - Train Loss: 0.6641 - Val Loss: 0.6794\n","Val Metrics: Precision=0.6076, Recall=0.6186, F1=0.5966\n","Epoch 15/30 - Train Loss: 0.6637 - Val Loss: 0.6785\n","Val Metrics: Precision=0.6041, Recall=0.6148, F1=0.5969\n","Epoch 16/30 - Train Loss: 0.6630 - Val Loss: 0.6586\n","Val Metrics: Precision=0.6026, Recall=0.5982, F1=0.5998\n","Epoch 17/30 - Train Loss: 0.6623 - Val Loss: 0.6563\n","Val Metrics: Precision=0.6057, Recall=0.5957, F1=0.5981\n","Epoch 18/30 - Train Loss: 0.6612 - Val Loss: 0.6882\n","Val Metrics: Precision=0.6033, Recall=0.6133, F1=0.5861\n","Epoch 19/30 - Train Loss: 0.6628 - Val Loss: 0.6599\n","Val Metrics: Precision=0.6048, Recall=0.6036, F1=0.6042\n","Epoch 20/30 - Train Loss: 0.6608 - Val Loss: 0.6632\n","Val Metrics: Precision=0.6076, Recall=0.6095, F1=0.6084\n","Epoch 21/30 - Train Loss: 0.6596 - Val Loss: 0.6586\n","Val Metrics: Precision=0.6043, Recall=0.5987, F1=0.6006\n","Epoch 22/30 - Train Loss: 0.6591 - Val Loss: 0.6536\n","Val Metrics: Precision=0.6002, Recall=0.5839, F1=0.5853\n","Epoch 23/30 - Train Loss: 0.6584 - Val Loss: 0.6542\n","Val Metrics: Precision=0.6026, Recall=0.5876, F1=0.5895\n","Epoch 24/30 - Train Loss: 0.6588 - Val Loss: 0.6543\n","Val Metrics: Precision=0.5985, Recall=0.5828, F1=0.5842\n","Epoch 25/30 - Train Loss: 0.6562 - Val Loss: 0.6850\n","Val Metrics: Precision=0.5990, Recall=0.6092, F1=0.5894\n","Epoch 26/30 - Train Loss: 0.6571 - Val Loss: 0.6608\n","Val Metrics: Precision=0.6037, Recall=0.5988, F1=0.6006\n","Epoch 27/30 - Train Loss: 0.6566 - Val Loss: 0.6555\n","Val Metrics: Precision=0.6093, Recall=0.5980, F1=0.6005\n","Epoch 28/30 - Train Loss: 0.6551 - Val Loss: 0.6555\n","Val Metrics: Precision=0.6045, Recall=0.5920, F1=0.5942\n","Epoch 29/30 - Train Loss: 0.6545 - Val Loss: 0.6563\n","Val Metrics: Precision=0.6071, Recall=0.5955, F1=0.5979\n","Epoch 30/30 - Train Loss: 0.6565 - Val Loss: 0.6625\n","Val Metrics: Precision=0.5971, Recall=0.5958, F1=0.5964\n","\n","Test Results:\n","Loss: 0.6001\n","Precision: 0.6766\n","Recall: 0.6071\n","F1 Score: 0.6216\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/av_sv_lst_energy_efficiency_model.pth\n","saved!\n","\n","\n","ablation: av_sv_fp\n","Training data shape: (27922, 4097)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 4097)\n","Test data shape: (2756, 4097)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.6941 - Val Loss: 0.6835\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 2/30 - Train Loss: 0.6936 - Val Loss: 0.6861\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 3/30 - Train Loss: 0.6933 - Val Loss: 0.6876\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 4/30 - Train Loss: 0.6892 - Val Loss: 0.6814\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 5/30 - Train Loss: 0.6837 - Val Loss: 0.6701\n","Val Metrics: Precision=0.5928, Recall=0.6023, F1=0.5807\n","Epoch 6/30 - Train Loss: 0.6831 - Val Loss: 0.6779\n","Val Metrics: Precision=0.6136, Recall=0.6140, F1=0.5576\n","Epoch 7/30 - Train Loss: 0.6810 - Val Loss: 0.6821\n","Val Metrics: Precision=0.6108, Recall=0.6019, F1=0.5289\n","Epoch 8/30 - Train Loss: 0.6813 - Val Loss: 0.6698\n","Val Metrics: Precision=0.6141, Recall=0.6219, F1=0.5819\n","Epoch 9/30 - Train Loss: 0.6781 - Val Loss: 0.6671\n","Val Metrics: Precision=0.6116, Recall=0.6198, F1=0.5815\n","Epoch 10/30 - Train Loss: 0.6784 - Val Loss: 0.6794\n","Val Metrics: Precision=0.6137, Recall=0.6079, F1=0.5403\n","Epoch 11/30 - Train Loss: 0.6771 - Val Loss: 0.6772\n","Val Metrics: Precision=0.6152, Recall=0.6120, F1=0.5489\n","Epoch 12/30 - Train Loss: 0.6788 - Val Loss: 0.6723\n","Val Metrics: Precision=0.6189, Recall=0.6222, F1=0.5709\n","Epoch 13/30 - Train Loss: 0.6766 - Val Loss: 0.6671\n","Val Metrics: Precision=0.6177, Recall=0.6259, F1=0.5857\n","Epoch 14/30 - Train Loss: 0.6773 - Val Loss: 0.6725\n","Val Metrics: Precision=0.6216, Recall=0.6231, F1=0.5679\n","Epoch 15/30 - Train Loss: 0.6752 - Val Loss: 0.6629\n","Val Metrics: Precision=0.6194, Recall=0.6290, F1=0.5926\n","Epoch 16/30 - Train Loss: 0.6766 - Val Loss: 0.6724\n","Val Metrics: Precision=0.6249, Recall=0.6246, F1=0.5658\n","Epoch 17/30 - Train Loss: 0.6737 - Val Loss: 0.6802\n","Val Metrics: Precision=0.6229, Recall=0.6104, F1=0.5326\n","Epoch 18/30 - Train Loss: 0.6754 - Val Loss: 0.6588\n","Val Metrics: Precision=0.6084, Recall=0.6178, F1=0.5844\n","Epoch 19/30 - Train Loss: 0.6743 - Val Loss: 0.6578\n","Val Metrics: Precision=0.6061, Recall=0.6156, F1=0.5842\n","Epoch 20/30 - Train Loss: 0.6724 - Val Loss: 0.6651\n","Val Metrics: Precision=0.6221, Recall=0.6270, F1=0.5781\n","Epoch 21/30 - Train Loss: 0.6736 - Val Loss: 0.6703\n","Val Metrics: Precision=0.6225, Recall=0.6210, F1=0.5604\n","Epoch 22/30 - Train Loss: 0.6743 - Val Loss: 0.6646\n","Val Metrics: Precision=0.6229, Recall=0.6281, F1=0.5799\n","Epoch 23/30 - Train Loss: 0.6729 - Val Loss: 0.6765\n","Val Metrics: Precision=0.6238, Recall=0.6136, F1=0.5392\n","Epoch 24/30 - Train Loss: 0.6742 - Val Loss: 0.6595\n","Val Metrics: Precision=0.6122, Recall=0.6202, F1=0.5810\n","Epoch 25/30 - Train Loss: 0.6733 - Val Loss: 0.6732\n","Val Metrics: Precision=0.6196, Recall=0.6128, F1=0.5434\n","Epoch 26/30 - Train Loss: 0.6722 - Val Loss: 0.6660\n","Val Metrics: Precision=0.6188, Recall=0.6202, F1=0.5650\n","Epoch 27/30 - Train Loss: 0.6713 - Val Loss: 0.6637\n","Val Metrics: Precision=0.6191, Recall=0.6228, F1=0.5723\n","Epoch 28/30 - Train Loss: 0.6710 - Val Loss: 0.6694\n","Val Metrics: Precision=0.6208, Recall=0.6179, F1=0.5550\n","Epoch 29/30 - Train Loss: 0.6722 - Val Loss: 0.6551\n","Val Metrics: Precision=0.6045, Recall=0.6132, F1=0.5791\n","Epoch 30/30 - Train Loss: 0.6710 - Val Loss: 0.6691\n","Val Metrics: Precision=0.6193, Recall=0.6153, F1=0.5506\n","\n","Test Results:\n","Loss: 0.5854\n","Precision: 0.6589\n","Recall: 0.6801\n","F1 Score: 0.6670\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/av_sv_fp_energy_efficiency_model.pth\n","saved!\n","\n","\n","ablation: sv_lst_fp\n","Training data shape: (27922, 2052)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 2052)\n","Test data shape: (2756, 2052)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.6936 - Val Loss: 0.6785\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 2/30 - Train Loss: 0.6878 - Val Loss: 0.6777\n","Val Metrics: Precision=0.6082, Recall=0.5027, F1=0.4039\n","Epoch 3/30 - Train Loss: 0.6848 - Val Loss: 0.6761\n","Val Metrics: Precision=0.5908, Recall=0.5054, F1=0.4141\n","Epoch 4/30 - Train Loss: 0.6829 - Val Loss: 0.6746\n","Val Metrics: Precision=0.5774, Recall=0.5046, F1=0.4129\n","Epoch 5/30 - Train Loss: 0.6828 - Val Loss: 0.6732\n","Val Metrics: Precision=0.5979, Recall=0.5056, F1=0.4142\n","Epoch 6/30 - Train Loss: 0.6821 - Val Loss: 0.6719\n","Val Metrics: Precision=0.6013, Recall=0.5164, F1=0.4471\n","Epoch 7/30 - Train Loss: 0.6800 - Val Loss: 0.6706\n","Val Metrics: Precision=0.6076, Recall=0.5147, F1=0.4410\n","Epoch 8/30 - Train Loss: 0.6807 - Val Loss: 0.6695\n","Val Metrics: Precision=0.6208, Recall=0.5260, F1=0.4683\n","Epoch 9/30 - Train Loss: 0.6803 - Val Loss: 0.6684\n","Val Metrics: Precision=0.6315, Recall=0.5295, F1=0.4746\n","Epoch 10/30 - Train Loss: 0.6787 - Val Loss: 0.6682\n","Val Metrics: Precision=0.6083, Recall=0.5482, F1=0.5231\n","Epoch 11/30 - Train Loss: 0.6770 - Val Loss: 0.6664\n","Val Metrics: Precision=0.6299, Recall=0.5223, F1=0.4572\n","Epoch 12/30 - Train Loss: 0.6776 - Val Loss: 0.6660\n","Val Metrics: Precision=0.6270, Recall=0.5233, F1=0.4602\n","Epoch 13/30 - Train Loss: 0.6771 - Val Loss: 0.6656\n","Val Metrics: Precision=0.6127, Recall=0.5420, F1=0.5084\n","Epoch 14/30 - Train Loss: 0.6766 - Val Loss: 0.6648\n","Val Metrics: Precision=0.6226, Recall=0.5316, F1=0.4818\n","Epoch 15/30 - Train Loss: 0.6760 - Val Loss: 0.6640\n","Val Metrics: Precision=0.6283, Recall=0.5359, F1=0.4903\n","Epoch 16/30 - Train Loss: 0.6745 - Val Loss: 0.6631\n","Val Metrics: Precision=0.6186, Recall=0.5490, F1=0.5213\n","Epoch 17/30 - Train Loss: 0.6761 - Val Loss: 0.6630\n","Val Metrics: Precision=0.6429, Recall=0.5287, F1=0.4703\n","Epoch 18/30 - Train Loss: 0.6751 - Val Loss: 0.6627\n","Val Metrics: Precision=0.6391, Recall=0.5299, F1=0.4739\n","Epoch 19/30 - Train Loss: 0.6750 - Val Loss: 0.6627\n","Val Metrics: Precision=0.6275, Recall=0.5278, F1=0.4712\n","Epoch 20/30 - Train Loss: 0.6743 - Val Loss: 0.6623\n","Val Metrics: Precision=0.6110, Recall=0.5458, F1=0.5173\n","Epoch 21/30 - Train Loss: 0.6729 - Val Loss: 0.6617\n","Val Metrics: Precision=0.6265, Recall=0.5319, F1=0.4815\n","Epoch 22/30 - Train Loss: 0.6732 - Val Loss: 0.6627\n","Val Metrics: Precision=0.6110, Recall=0.5599, F1=0.5451\n","Epoch 23/30 - Train Loss: 0.6717 - Val Loss: 0.6612\n","Val Metrics: Precision=0.6358, Recall=0.5311, F1=0.4774\n","Epoch 24/30 - Train Loss: 0.6733 - Val Loss: 0.6615\n","Val Metrics: Precision=0.6340, Recall=0.5254, F1=0.4640\n","Epoch 25/30 - Train Loss: 0.6750 - Val Loss: 0.6611\n","Val Metrics: Precision=0.6268, Recall=0.5452, F1=0.5112\n","Epoch 26/30 - Train Loss: 0.6714 - Val Loss: 0.6607\n","Val Metrics: Precision=0.6168, Recall=0.5557, F1=0.5354\n","Epoch 27/30 - Train Loss: 0.6717 - Val Loss: 0.6605\n","Val Metrics: Precision=0.6158, Recall=0.5501, F1=0.5245\n","Epoch 28/30 - Train Loss: 0.6744 - Val Loss: 0.6606\n","Val Metrics: Precision=0.6177, Recall=0.5509, F1=0.5256\n","Epoch 29/30 - Train Loss: 0.6704 - Val Loss: 0.6609\n","Val Metrics: Precision=0.6021, Recall=0.5632, F1=0.5541\n","Epoch 30/30 - Train Loss: 0.6713 - Val Loss: 0.6596\n","Val Metrics: Precision=0.6261, Recall=0.5577, F1=0.5364\n","\n","Test Results:\n","Loss: 0.6286\n","Precision: 0.6763\n","Recall: 0.5868\n","F1 Score: 0.5977\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/sv_lst_fp_energy_efficiency_model.pth\n","saved!\n","\n","\n"]}]},{"cell_type":"markdown","source":["**Linear Prediction Head**"],"metadata":{"id":"F2gyjgIuhEGC"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","\n","class EnergyEfficiencyLinear(nn.Module):\n","    def __init__(self, input_dim=4100):\n","        super(EnergyEfficiencyLinear, self).__init__()\n","\n","        # single layer -> binary classigication\n","        self.prediction_head = nn.Sequential(\n","            nn.Linear(input_dim, 1),\n","            nn.Sigmoid()\n","        )\n","\n","    def forward(self, x):\n","        return self.prediction_head(x)"],"metadata":{"id":"8LJBxrMuhDvL","executionInfo":{"status":"ok","timestamp":1745961932088,"user_tz":240,"elapsed":6,"user":{"displayName":"Eric Zheng","userId":"09751706780638879012"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def train_linear_model(train_loader, val_loader, test_loader, input_dim, device=None):\n","    if device is None:\n","        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","    # initialize model\n","    model = EnergyEfficiencyLinear(input_dim).to(device)\n","\n","    # calculate class weights - make sure each class are equally important\n","    num_efficient = np.sum(y_train == 1)\n","    num_inefficient = np.sum(y_train == 0)\n","    total = num_efficient + num_inefficient\n","\n","    weight_efficient = total / (2 * num_efficient)\n","    weight_inefficient = total / (2 * num_inefficient)\n","\n","    print(f\"distribution: efficient={num_efficient}, inefficient={num_inefficient}\")\n","    print(f\"weights: efficient={weight_efficient:.4f}, inefficient={weight_inefficient:.4f}\")\n","\n","    # adam optimizer with learning rate 0.0001\n","    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n","\n","    # training loop\n","    num_epochs = 30\n","    best_val_f1 = 0\n","    best_model = None\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        train_loss = 0.0\n","\n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            # forward pass\n","            outputs = model(inputs).squeeze()\n","\n","            # calculate loss with class weights\n","            weights = torch.where(labels == 1,\n","                               torch.tensor(weight_efficient, device=device),\n","                               torch.tensor(weight_inefficient, device=device))\n","\n","            criterion = nn.BCELoss(weight=weights)\n","            loss = criterion(outputs, labels)\n","\n","            # backward pass and optimize\n","            optimizer.zero_grad()\n","            loss.backward()\n","            optimizer.step()\n","\n","            train_loss += loss.item() * inputs.size(0)\n","\n","        train_loss = train_loss / len(train_loader.dataset)\n","\n","        # evaluate on validation set\n","        val_loss, val_metrics = evaluate_model(model, val_loader, device)\n","\n","        print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f}\")\n","        print(f\"Val Metrics: Precision={val_metrics['precision']:.4f}, Recall={val_metrics['recall']:.4f}, F1={val_metrics['f1']:.4f}\")\n","\n","        # save best model based on validation F1 score\n","        if val_metrics['f1'] > best_val_f1:\n","            best_val_f1 = val_metrics['f1']\n","            best_model = model.state_dict().copy()\n","\n","    # load best model\n","    model.load_state_dict(best_model)\n","\n","    # evaluation on test set\n","    test_loss, test_metrics = evaluate_linear_model(model, test_loader, device)\n","\n","    print(\"\\nTest Results:\")\n","    print(f\"Loss: {test_loss:.4f}\")\n","    print(f\"Precision: {test_metrics['precision']:.4f}\")\n","    print(f\"Recall: {test_metrics['recall']:.4f}\")\n","    print(f\"F1 Score: {test_metrics['f1']:.4f}\")\n","\n","    return model, test_metrics\n","\n","\n","def evaluate_linear_model(model, data_loader, device):\n","    model.eval()\n","    running_loss = 0.0\n","    all_preds = []\n","    all_labels = []\n","\n","    with torch.no_grad():\n","        for inputs, labels in data_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","\n","            # forward pass + remove dim of 1\n","            outputs = model(inputs).squeeze()\n","\n","            # binary cross entrpy\n","            criterion = nn.BCELoss()\n","            loss = criterion(outputs, labels)\n","\n","            running_loss += loss.item() * inputs.size(0)\n","\n","            # convert outputs to binary predictions\n","            preds = (outputs > 0.5).float()\n","\n","            all_preds.extend(preds.cpu().numpy())\n","            all_labels.extend(labels.cpu().numpy())\n","\n","    # calculate loss\n","    loss = running_loss / len(data_loader.dataset)\n","\n","    # calculate metrics\n","    precision, recall, f1, _ = precision_recall_fscore_support(\n","        all_labels, all_preds, average='macro')\n","\n","    metrics = {\n","        'precision': precision,\n","        'recall': recall,\n","        'f1': f1\n","    }\n","\n","    return loss, metrics\n"],"metadata":{"id":"MSLocWariZRQ","executionInfo":{"status":"ok","timestamp":1745961933813,"user_tz":240,"elapsed":7,"user":{"displayName":"Eric Zheng","userId":"09751706780638879012"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["**Train Linear Model**"],"metadata":{"id":"RAodxjb4jztx"}},{"cell_type":"code","source":["# set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","# input dim\n","input_dim = X_train.shape[1]\n","\n","# train model\n","linear_model, linear_metrics = train_model(train_loader, val_loader, test_loader, input_dim, device)\n","\n","# save trained model\n","torch.save(model.state_dict(), '/content/drive/MyDrive/semester 4/csci 1470: final project/energy_efficiency_linear_model.pth')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oPw6aKe3h9t0","executionInfo":{"status":"ok","timestamp":1745809865918,"user_tz":240,"elapsed":149483,"user":{"displayName":"Eric Zheng","userId":"09751706780638879012"}},"outputId":"ab404a31-7a6c-43a4-867b-533d92fb735d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.6898 - Val Loss: 0.6945\n","Val Metrics: Precision=0.5890, Recall=0.5978, F1=0.5734\n","Epoch 2/30 - Train Loss: 0.6855 - Val Loss: 0.6921\n","Val Metrics: Precision=0.5948, Recall=0.6046, F1=0.5859\n","Epoch 3/30 - Train Loss: 0.6834 - Val Loss: 0.6856\n","Val Metrics: Precision=0.5915, Recall=0.5949, F1=0.5926\n","Epoch 4/30 - Train Loss: 0.6809 - Val Loss: 0.6823\n","Val Metrics: Precision=0.5952, Recall=0.5978, F1=0.5962\n","Epoch 5/30 - Train Loss: 0.6788 - Val Loss: 0.6797\n","Val Metrics: Precision=0.5970, Recall=0.6016, F1=0.5982\n","Epoch 6/30 - Train Loss: 0.6780 - Val Loss: 0.6765\n","Val Metrics: Precision=0.5975, Recall=0.5991, F1=0.5982\n","Epoch 7/30 - Train Loss: 0.6775 - Val Loss: 0.6718\n","Val Metrics: Precision=0.6004, Recall=0.5899, F1=0.5920\n","Epoch 8/30 - Train Loss: 0.6762 - Val Loss: 0.6690\n","Val Metrics: Precision=0.5996, Recall=0.5825, F1=0.5837\n","Epoch 9/30 - Train Loss: 0.6759 - Val Loss: 0.6681\n","Val Metrics: Precision=0.6031, Recall=0.5900, F1=0.5921\n","Epoch 10/30 - Train Loss: 0.6741 - Val Loss: 0.6692\n","Val Metrics: Precision=0.6015, Recall=0.6009, F1=0.6012\n","Epoch 11/30 - Train Loss: 0.6735 - Val Loss: 0.6649\n","Val Metrics: Precision=0.6088, Recall=0.5924, F1=0.5946\n","Epoch 12/30 - Train Loss: 0.6736 - Val Loss: 0.6674\n","Val Metrics: Precision=0.6025, Recall=0.6009, F1=0.6016\n","Epoch 13/30 - Train Loss: 0.6719 - Val Loss: 0.6623\n","Val Metrics: Precision=0.6051, Recall=0.5858, F1=0.5870\n","Epoch 14/30 - Train Loss: 0.6714 - Val Loss: 0.6643\n","Val Metrics: Precision=0.6089, Recall=0.6032, F1=0.6051\n","Epoch 15/30 - Train Loss: 0.6715 - Val Loss: 0.6591\n","Val Metrics: Precision=0.6172, Recall=0.5343, F1=0.4894\n","Epoch 16/30 - Train Loss: 0.6700 - Val Loss: 0.6629\n","Val Metrics: Precision=0.6091, Recall=0.5961, F1=0.5986\n","Epoch 17/30 - Train Loss: 0.6710 - Val Loss: 0.6582\n","Val Metrics: Precision=0.6101, Recall=0.5634, F1=0.5518\n","Epoch 18/30 - Train Loss: 0.6700 - Val Loss: 0.6601\n","Val Metrics: Precision=0.6026, Recall=0.5869, F1=0.5887\n","Epoch 19/30 - Train Loss: 0.6676 - Val Loss: 0.6594\n","Val Metrics: Precision=0.6063, Recall=0.5854, F1=0.5864\n","Epoch 20/30 - Train Loss: 0.6680 - Val Loss: 0.6569\n","Val Metrics: Precision=0.6116, Recall=0.5693, F1=0.5613\n","Epoch 21/30 - Train Loss: 0.6675 - Val Loss: 0.6589\n","Val Metrics: Precision=0.6085, Recall=0.5889, F1=0.5905\n","Epoch 22/30 - Train Loss: 0.6660 - Val Loss: 0.6567\n","Val Metrics: Precision=0.6060, Recall=0.5603, F1=0.5476\n","Epoch 23/30 - Train Loss: 0.6673 - Val Loss: 0.6556\n","Val Metrics: Precision=0.6079, Recall=0.5676, F1=0.5597\n","Epoch 24/30 - Train Loss: 0.6654 - Val Loss: 0.6575\n","Val Metrics: Precision=0.6001, Recall=0.5779, F1=0.5776\n","Epoch 25/30 - Train Loss: 0.6665 - Val Loss: 0.6557\n","Val Metrics: Precision=0.6070, Recall=0.5652, F1=0.5558\n","Epoch 26/30 - Train Loss: 0.6636 - Val Loss: 0.6573\n","Val Metrics: Precision=0.5972, Recall=0.5777, F1=0.5778\n","Epoch 27/30 - Train Loss: 0.6643 - Val Loss: 0.6582\n","Val Metrics: Precision=0.6033, Recall=0.5886, F1=0.5906\n","Epoch 28/30 - Train Loss: 0.6645 - Val Loss: 0.6551\n","Val Metrics: Precision=0.6061, Recall=0.5727, F1=0.5685\n","Epoch 29/30 - Train Loss: 0.6644 - Val Loss: 0.6560\n","Val Metrics: Precision=0.5998, Recall=0.5739, F1=0.5720\n","Epoch 30/30 - Train Loss: 0.6613 - Val Loss: 0.6549\n","Val Metrics: Precision=0.6083, Recall=0.5767, F1=0.5739\n","\n","Test Results:\n","Loss: 0.6164\n","Precision: 0.6818\n","Recall: 0.6091\n","F1 Score: 0.6242\n"]}]},{"cell_type":"markdown","source":["**Ablation Studies**"],"metadata":{"id":"K-EL2vFrj3WB"}},{"cell_type":"code","source":["# set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","ablations = ['av', 'fp', 'lst', 'sv']\n","for ablation in ablations:\n","  print(f\"ablation: {ablation}\")\n","  # get data and loaders\n","  data_loader_dict = get_loaders(ablation)\n","\n","  train_loader, val_loader, test_loader = data_loader_dict['loaders']\n","  X_train, y_train = data_loader_dict['data']\n","\n","  # input dim\n","  input_dim = X_train.shape[1]\n","\n","  # train model\n","  model, test_metrics = train_linear_model(train_loader, val_loader, test_loader, input_dim, device)\n","\n","  # model path\n","  model_path = '/content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/' + ablation + '_energy_efficiency_linear_model.pth'\n","  print(f\"path: {model_path}\")\n","\n","  # save trained model\n","  torch.save(model.state_dict(), model_path)\n","  print(f\"saved!\\n\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6jWpGDyBdDZL","executionInfo":{"status":"ok","timestamp":1745962483473,"user_tz":240,"elapsed":294673,"user":{"displayName":"Eric Zheng","userId":"09751706780638879012"}},"outputId":"c7d4190e-c353-405c-f60a-f86d8578ca2b"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n","ablation: av\n","Training data shape: (27922, 2048)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 2048)\n","Test data shape: (2756, 2048)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.6745 - Val Loss: 0.6989\n","Val Metrics: Precision=0.5939, Recall=0.5965, F1=0.5474\n","Epoch 2/30 - Train Loss: 0.6679 - Val Loss: 0.6551\n","Val Metrics: Precision=0.5865, Recall=0.5934, F1=0.5859\n","Epoch 3/30 - Train Loss: 0.6653 - Val Loss: 0.6411\n","Val Metrics: Precision=0.5806, Recall=0.5794, F1=0.5799\n","Epoch 4/30 - Train Loss: 0.6626 - Val Loss: 0.6920\n","Val Metrics: Precision=0.5929, Recall=0.5974, F1=0.5536\n","Epoch 5/30 - Train Loss: 0.6615 - Val Loss: 0.6824\n","Val Metrics: Precision=0.5901, Recall=0.5972, F1=0.5630\n","Epoch 6/30 - Train Loss: 0.6596 - Val Loss: 0.6540\n","Val Metrics: Precision=0.5900, Recall=0.5980, F1=0.5879\n","Epoch 7/30 - Train Loss: 0.6588 - Val Loss: 0.6700\n","Val Metrics: Precision=0.5915, Recall=0.6007, F1=0.5779\n","Epoch 8/30 - Train Loss: 0.6578 - Val Loss: 0.6705\n","Val Metrics: Precision=0.5902, Recall=0.5992, F1=0.5748\n","Epoch 9/30 - Train Loss: 0.6567 - Val Loss: 0.6608\n","Val Metrics: Precision=0.5920, Recall=0.6013, F1=0.5852\n","Epoch 10/30 - Train Loss: 0.6558 - Val Loss: 0.6681\n","Val Metrics: Precision=0.5936, Recall=0.6030, F1=0.5798\n","Epoch 11/30 - Train Loss: 0.6549 - Val Loss: 0.6721\n","Val Metrics: Precision=0.5906, Recall=0.5994, F1=0.5732\n","Epoch 12/30 - Train Loss: 0.6543 - Val Loss: 0.6661\n","Val Metrics: Precision=0.5911, Recall=0.6005, F1=0.5794\n","Epoch 13/30 - Train Loss: 0.6537 - Val Loss: 0.6671\n","Val Metrics: Precision=0.5917, Recall=0.6011, F1=0.5787\n","Epoch 14/30 - Train Loss: 0.6524 - Val Loss: 0.6508\n","Val Metrics: Precision=0.5867, Recall=0.5939, F1=0.5857\n","Epoch 15/30 - Train Loss: 0.6521 - Val Loss: 0.6973\n","Val Metrics: Precision=0.5958, Recall=0.5987, F1=0.5498\n","Epoch 16/30 - Train Loss: 0.6513 - Val Loss: 0.6673\n","Val Metrics: Precision=0.5953, Recall=0.6050, F1=0.5821\n","Epoch 17/30 - Train Loss: 0.6510 - Val Loss: 0.6468\n","Val Metrics: Precision=0.5891, Recall=0.5948, F1=0.5896\n","Epoch 18/30 - Train Loss: 0.6505 - Val Loss: 0.6605\n","Val Metrics: Precision=0.5914, Recall=0.6007, F1=0.5841\n","Epoch 19/30 - Train Loss: 0.6502 - Val Loss: 0.6536\n","Val Metrics: Precision=0.5892, Recall=0.5971, F1=0.5874\n","Epoch 20/30 - Train Loss: 0.6501 - Val Loss: 0.6802\n","Val Metrics: Precision=0.5921, Recall=0.5999, F1=0.5677\n","Epoch 21/30 - Train Loss: 0.6489 - Val Loss: 0.6514\n","Val Metrics: Precision=0.5864, Recall=0.5935, F1=0.5856\n","Epoch 22/30 - Train Loss: 0.6489 - Val Loss: 0.6590\n","Val Metrics: Precision=0.5857, Recall=0.5942, F1=0.5799\n","Epoch 23/30 - Train Loss: 0.6481 - Val Loss: 0.6460\n","Val Metrics: Precision=0.5923, Recall=0.5972, F1=0.5934\n","Epoch 24/30 - Train Loss: 0.6480 - Val Loss: 0.6888\n","Val Metrics: Precision=0.5926, Recall=0.5988, F1=0.5605\n","Epoch 25/30 - Train Loss: 0.6479 - Val Loss: 0.6733\n","Val Metrics: Precision=0.5944, Recall=0.6037, F1=0.5776\n","Epoch 26/30 - Train Loss: 0.6471 - Val Loss: 0.6433\n","Val Metrics: Precision=0.5900, Recall=0.5935, F1=0.5911\n","Epoch 27/30 - Train Loss: 0.6470 - Val Loss: 0.6476\n","Val Metrics: Precision=0.5898, Recall=0.5961, F1=0.5901\n","Epoch 28/30 - Train Loss: 0.6465 - Val Loss: 0.6655\n","Val Metrics: Precision=0.5906, Recall=0.5999, F1=0.5805\n","Epoch 29/30 - Train Loss: 0.6457 - Val Loss: 0.6361\n","Val Metrics: Precision=0.5892, Recall=0.5858, F1=0.5870\n","Epoch 30/30 - Train Loss: 0.6457 - Val Loss: 0.6602\n","Val Metrics: Precision=0.5902, Recall=0.5993, F1=0.5837\n","\n","Test Results:\n","Loss: 0.5770\n","Precision: 0.6233\n","Recall: 0.6303\n","F1 Score: 0.6264\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/av_energy_efficiency_linear_model.pth\n","saved!\n","\n","\n","ablation: fp\n","Training data shape: (27922, 1)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 1)\n","Test data shape: (2756, 1)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.6954 - Val Loss: 0.6476\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 2/30 - Train Loss: 0.6937 - Val Loss: 0.6465\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 3/30 - Train Loss: 0.6937 - Val Loss: 0.6468\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 4/30 - Train Loss: 0.6938 - Val Loss: 0.6472\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 5/30 - Train Loss: 0.6938 - Val Loss: 0.6482\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 6/30 - Train Loss: 0.6936 - Val Loss: 0.6466\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 7/30 - Train Loss: 0.6938 - Val Loss: 0.6467\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 8/30 - Train Loss: 0.6938 - Val Loss: 0.6481\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 9/30 - Train Loss: 0.6935 - Val Loss: 0.6473\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 10/30 - Train Loss: 0.6935 - Val Loss: 0.6476\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 11/30 - Train Loss: 0.6936 - Val Loss: 0.6469\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 12/30 - Train Loss: 0.6937 - Val Loss: 0.6475\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 13/30 - Train Loss: 0.6938 - Val Loss: 0.6469\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 14/30 - Train Loss: 0.6937 - Val Loss: 0.6481\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 15/30 - Train Loss: 0.6938 - Val Loss: 0.6469\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 16/30 - Train Loss: 0.6937 - Val Loss: 0.6475\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 17/30 - Train Loss: 0.6937 - Val Loss: 0.6470\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 18/30 - Train Loss: 0.6938 - Val Loss: 0.6472\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 19/30 - Train Loss: 0.6938 - Val Loss: 0.6464\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 20/30 - Train Loss: 0.6936 - Val Loss: 0.6474\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 21/30 - Train Loss: 0.6938 - Val Loss: 0.6465\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 22/30 - Train Loss: 0.6937 - Val Loss: 0.6467\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 23/30 - Train Loss: 0.6937 - Val Loss: 0.6476\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 24/30 - Train Loss: 0.6938 - Val Loss: 0.6472\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 25/30 - Train Loss: 0.6937 - Val Loss: 0.6478\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 26/30 - Train Loss: 0.6938 - Val Loss: 0.6472\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 27/30 - Train Loss: 0.6937 - Val Loss: 0.6476\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 28/30 - Train Loss: 0.6937 - Val Loss: 0.6477\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 29/30 - Train Loss: 0.6938 - Val Loss: 0.6481\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 30/30 - Train Loss: 0.6938 - Val Loss: 0.6475\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","\n","Test Results:\n","Loss: 0.6955\n","Precision: 0.1096\n","Recall: 0.5000\n","F1 Score: 0.1798\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/fp_energy_efficiency_linear_model.pth\n","saved!\n","\n","\n","ablation: lst\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Training data shape: (27922, 3)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 3)\n","Test data shape: (2756, 3)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.7063 - Val Loss: 0.7349\n","Val Metrics: Precision=0.1736, Recall=0.5000, F1=0.2577\n","Epoch 2/30 - Train Loss: 0.6987 - Val Loss: 0.7183\n","Val Metrics: Precision=0.1736, Recall=0.5000, F1=0.2577\n","Epoch 3/30 - Train Loss: 0.6950 - Val Loss: 0.7079\n","Val Metrics: Precision=0.1736, Recall=0.5000, F1=0.2577\n","Epoch 4/30 - Train Loss: 0.6933 - Val Loss: 0.7016\n","Val Metrics: Precision=0.1736, Recall=0.5000, F1=0.2577\n","Epoch 5/30 - Train Loss: 0.6924 - Val Loss: 0.6974\n","Val Metrics: Precision=0.5859, Recall=0.5023, F1=0.2657\n","Epoch 6/30 - Train Loss: 0.6919 - Val Loss: 0.6946\n","Val Metrics: Precision=0.5492, Recall=0.5267, F1=0.3901\n","Epoch 7/30 - Train Loss: 0.6915 - Val Loss: 0.6927\n","Val Metrics: Precision=0.5423, Recall=0.5449, F1=0.5094\n","Epoch 8/30 - Train Loss: 0.6912 - Val Loss: 0.6916\n","Val Metrics: Precision=0.5546, Recall=0.5593, F1=0.5517\n","Epoch 9/30 - Train Loss: 0.6909 - Val Loss: 0.6905\n","Val Metrics: Precision=0.5745, Recall=0.5739, F1=0.5742\n","Epoch 10/30 - Train Loss: 0.6906 - Val Loss: 0.6898\n","Val Metrics: Precision=0.5774, Recall=0.5720, F1=0.5733\n","Epoch 11/30 - Train Loss: 0.6903 - Val Loss: 0.6894\n","Val Metrics: Precision=0.5812, Recall=0.5743, F1=0.5757\n","Epoch 12/30 - Train Loss: 0.6901 - Val Loss: 0.6888\n","Val Metrics: Precision=0.5841, Recall=0.5735, F1=0.5746\n","Epoch 13/30 - Train Loss: 0.6898 - Val Loss: 0.6885\n","Val Metrics: Precision=0.5859, Recall=0.5741, F1=0.5752\n","Epoch 14/30 - Train Loss: 0.6895 - Val Loss: 0.6881\n","Val Metrics: Precision=0.5912, Recall=0.5763, F1=0.5772\n","Epoch 15/30 - Train Loss: 0.6893 - Val Loss: 0.6876\n","Val Metrics: Precision=0.5924, Recall=0.5733, F1=0.5728\n","Epoch 16/30 - Train Loss: 0.6890 - Val Loss: 0.6873\n","Val Metrics: Precision=0.5904, Recall=0.5724, F1=0.5721\n","Epoch 17/30 - Train Loss: 0.6888 - Val Loss: 0.6871\n","Val Metrics: Precision=0.5888, Recall=0.5715, F1=0.5713\n","Epoch 18/30 - Train Loss: 0.6885 - Val Loss: 0.6866\n","Val Metrics: Precision=0.5945, Recall=0.5735, F1=0.5726\n","Epoch 19/30 - Train Loss: 0.6883 - Val Loss: 0.6864\n","Val Metrics: Precision=0.5960, Recall=0.5748, F1=0.5741\n","Epoch 20/30 - Train Loss: 0.6880 - Val Loss: 0.6859\n","Val Metrics: Precision=0.5946, Recall=0.5712, F1=0.5693\n","Epoch 21/30 - Train Loss: 0.6878 - Val Loss: 0.6854\n","Val Metrics: Precision=0.5948, Recall=0.5679, F1=0.5643\n","Epoch 22/30 - Train Loss: 0.6876 - Val Loss: 0.6850\n","Val Metrics: Precision=0.5983, Recall=0.5694, F1=0.5655\n","Epoch 23/30 - Train Loss: 0.6873 - Val Loss: 0.6846\n","Val Metrics: Precision=0.5991, Recall=0.5692, F1=0.5649\n","Epoch 24/30 - Train Loss: 0.6871 - Val Loss: 0.6843\n","Val Metrics: Precision=0.6005, Recall=0.5693, F1=0.5647\n","Epoch 25/30 - Train Loss: 0.6869 - Val Loss: 0.6840\n","Val Metrics: Precision=0.5995, Recall=0.5690, F1=0.5645\n","Epoch 26/30 - Train Loss: 0.6866 - Val Loss: 0.6837\n","Val Metrics: Precision=0.6001, Recall=0.5695, F1=0.5651\n","Epoch 27/30 - Train Loss: 0.6864 - Val Loss: 0.6836\n","Val Metrics: Precision=0.5965, Recall=0.5681, F1=0.5639\n","Epoch 28/30 - Train Loss: 0.6862 - Val Loss: 0.6833\n","Val Metrics: Precision=0.5976, Recall=0.5686, F1=0.5645\n","Epoch 29/30 - Train Loss: 0.6860 - Val Loss: 0.6829\n","Val Metrics: Precision=0.5986, Recall=0.5689, F1=0.5647\n","Epoch 30/30 - Train Loss: 0.6858 - Val Loss: 0.6827\n","Val Metrics: Precision=0.5971, Recall=0.5686, F1=0.5646\n","\n","Test Results:\n","Loss: 0.7280\n","Precision: 0.6105\n","Recall: 0.5051\n","F1 Score: 0.1911\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/lst_energy_efficiency_linear_model.pth\n","saved!\n","\n","\n","ablation: sv\n","Training data shape: (27922, 2048)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 2048)\n","Test data shape: (2756, 2048)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.6809 - Val Loss: 0.6661\n","Val Metrics: Precision=0.5749, Recall=0.5813, F1=0.5732\n","Epoch 2/30 - Train Loss: 0.6689 - Val Loss: 0.6613\n","Val Metrics: Precision=0.5811, Recall=0.5879, F1=0.5798\n","Epoch 3/30 - Train Loss: 0.6645 - Val Loss: 0.6838\n","Val Metrics: Precision=0.5912, Recall=0.5976, F1=0.5603\n","Epoch 4/30 - Train Loss: 0.6618 - Val Loss: 0.6759\n","Val Metrics: Precision=0.5937, Recall=0.6026, F1=0.5746\n","Epoch 5/30 - Train Loss: 0.6595 - Val Loss: 0.6810\n","Val Metrics: Precision=0.5975, Recall=0.6055, F1=0.5719\n","Epoch 6/30 - Train Loss: 0.6579 - Val Loss: 0.6512\n","Val Metrics: Precision=0.5885, Recall=0.5944, F1=0.5889\n","Epoch 7/30 - Train Loss: 0.6572 - Val Loss: 0.6678\n","Val Metrics: Precision=0.5937, Recall=0.6033, F1=0.5833\n","Epoch 8/30 - Train Loss: 0.6555 - Val Loss: 0.6622\n","Val Metrics: Precision=0.5938, Recall=0.6033, F1=0.5878\n","Epoch 9/30 - Train Loss: 0.6543 - Val Loss: 0.6981\n","Val Metrics: Precision=0.6030, Recall=0.6064, F1=0.5576\n","Epoch 10/30 - Train Loss: 0.6532 - Val Loss: 0.6679\n","Val Metrics: Precision=0.5954, Recall=0.6051, F1=0.5833\n","Epoch 11/30 - Train Loss: 0.6522 - Val Loss: 0.7367\n","Val Metrics: Precision=0.5972, Recall=0.5809, F1=0.4931\n","Epoch 12/30 - Train Loss: 0.6513 - Val Loss: 0.6897\n","Val Metrics: Precision=0.6025, Recall=0.6092, F1=0.5692\n","Epoch 13/30 - Train Loss: 0.6507 - Val Loss: 0.6355\n","Val Metrics: Precision=0.5849, Recall=0.5827, F1=0.5836\n","Epoch 14/30 - Train Loss: 0.6499 - Val Loss: 0.6741\n","Val Metrics: Precision=0.5964, Recall=0.6056, F1=0.5785\n","Epoch 15/30 - Train Loss: 0.6497 - Val Loss: 0.6388\n","Val Metrics: Precision=0.5857, Recall=0.5866, F1=0.5861\n","Epoch 16/30 - Train Loss: 0.6484 - Val Loss: 0.6382\n","Val Metrics: Precision=0.5895, Recall=0.5909, F1=0.5901\n","Epoch 17/30 - Train Loss: 0.6480 - Val Loss: 0.7047\n","Val Metrics: Precision=0.6059, Recall=0.6058, F1=0.5490\n","Epoch 18/30 - Train Loss: 0.6470 - Val Loss: 0.6789\n","Val Metrics: Precision=0.6049, Recall=0.6143, F1=0.5828\n","Epoch 19/30 - Train Loss: 0.6468 - Val Loss: 0.6822\n","Val Metrics: Precision=0.6032, Recall=0.6119, F1=0.5780\n","Epoch 20/30 - Train Loss: 0.6464 - Val Loss: 0.6606\n","Val Metrics: Precision=0.6035, Recall=0.6140, F1=0.5975\n","Epoch 21/30 - Train Loss: 0.6458 - Val Loss: 0.6379\n","Val Metrics: Precision=0.5929, Recall=0.5950, F1=0.5937\n","Epoch 22/30 - Train Loss: 0.6452 - Val Loss: 0.6524\n","Val Metrics: Precision=0.5988, Recall=0.6077, F1=0.5970\n","Epoch 23/30 - Train Loss: 0.6447 - Val Loss: 0.6687\n","Val Metrics: Precision=0.5994, Recall=0.6095, F1=0.5871\n","Epoch 24/30 - Train Loss: 0.6441 - Val Loss: 0.6473\n","Val Metrics: Precision=0.5966, Recall=0.6038, F1=0.5967\n","Epoch 25/30 - Train Loss: 0.6436 - Val Loss: 0.6754\n","Val Metrics: Precision=0.6050, Recall=0.6150, F1=0.5864\n","Epoch 26/30 - Train Loss: 0.6435 - Val Loss: 0.6394\n","Val Metrics: Precision=0.5874, Recall=0.5902, F1=0.5883\n","Epoch 27/30 - Train Loss: 0.6426 - Val Loss: 0.6485\n","Val Metrics: Precision=0.5919, Recall=0.5988, F1=0.5919\n","Epoch 28/30 - Train Loss: 0.6427 - Val Loss: 0.6705\n","Val Metrics: Precision=0.6039, Recall=0.6145, F1=0.5915\n","Epoch 29/30 - Train Loss: 0.6416 - Val Loss: 0.6574\n","Val Metrics: Precision=0.5938, Recall=0.6029, F1=0.5897\n","Epoch 30/30 - Train Loss: 0.6417 - Val Loss: 0.6584\n","Val Metrics: Precision=0.5974, Recall=0.6070, F1=0.5927\n","\n","Test Results:\n","Loss: 0.5177\n","Precision: 0.6408\n","Recall: 0.5739\n","F1 Score: 0.5811\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/sv_energy_efficiency_linear_model.pth\n","saved!\n","\n","\n"]}]},{"cell_type":"code","source":["# set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","ablations = ['av_fp', 'av_lst', 'av_sv', 'sv_fp', 'sv_lst', 'lst_fp']\n","for ablation in ablations:\n","  print(f\"ablation: {ablation}\")\n","  # get data and loaders\n","  data_loader_dict = get_loaders(ablation)\n","\n","  train_loader, val_loader, test_loader = data_loader_dict['loaders']\n","  X_train, y_train = data_loader_dict['data']\n","\n","  # input dim\n","  input_dim = X_train.shape[1]\n","\n","  # train model\n","  model, test_metrics = train_linear_model(train_loader, val_loader, test_loader, input_dim, device)\n","\n","  # model path\n","  model_path = '/content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/' + ablation + '_energy_efficiency_linear_model.pth'\n","  print(f\"path: {model_path}\")\n","\n","  # save trained model\n","  torch.save(model.state_dict(), model_path)\n","  print(f\"saved!\\n\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rObhN3m9ep51","executionInfo":{"status":"ok","timestamp":1745963083226,"user_tz":240,"elapsed":469843,"user":{"displayName":"Eric Zheng","userId":"09751706780638879012"}},"outputId":"3ba53832-577e-4641-a40b-5e7100808118"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n","ablation: av_fp\n","Training data shape: (27922, 2049)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 2049)\n","Test data shape: (2756, 2049)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.6838 - Val Loss: 0.7813\n","Val Metrics: Precision=0.5962, Recall=0.5504, F1=0.4090\n","Epoch 2/30 - Train Loss: 0.6700 - Val Loss: 0.7781\n","Val Metrics: Precision=0.5937, Recall=0.5573, F1=0.4313\n","Epoch 3/30 - Train Loss: 0.6666 - Val Loss: 0.7210\n","Val Metrics: Precision=0.5932, Recall=0.5863, F1=0.5158\n","Epoch 4/30 - Train Loss: 0.6636 - Val Loss: 0.7476\n","Val Metrics: Precision=0.5943, Recall=0.5773, F1=0.4875\n","Epoch 5/30 - Train Loss: 0.6619 - Val Loss: 0.7844\n","Val Metrics: Precision=0.6001, Recall=0.5659, F1=0.4478\n","Epoch 6/30 - Train Loss: 0.6610 - Val Loss: 0.6989\n","Val Metrics: Precision=0.5919, Recall=0.5944, F1=0.5456\n","Epoch 7/30 - Train Loss: 0.6597 - Val Loss: 0.7117\n","Val Metrics: Precision=0.5891, Recall=0.5879, F1=0.5301\n","Epoch 8/30 - Train Loss: 0.6586 - Val Loss: 0.6756\n","Val Metrics: Precision=0.5916, Recall=0.6001, F1=0.5714\n","Epoch 9/30 - Train Loss: 0.6577 - Val Loss: 0.6942\n","Val Metrics: Precision=0.5921, Recall=0.5962, F1=0.5513\n","Epoch 10/30 - Train Loss: 0.6560 - Val Loss: 0.7228\n","Val Metrics: Precision=0.5915, Recall=0.5863, F1=0.5195\n","Epoch 11/30 - Train Loss: 0.6553 - Val Loss: 0.6705\n","Val Metrics: Precision=0.5966, Recall=0.6063, F1=0.5818\n","Epoch 12/30 - Train Loss: 0.6546 - Val Loss: 0.6730\n","Val Metrics: Precision=0.5959, Recall=0.6051, F1=0.5776\n","Epoch 13/30 - Train Loss: 0.6540 - Val Loss: 0.6846\n","Val Metrics: Precision=0.5972, Recall=0.6047, F1=0.5690\n","Epoch 14/30 - Train Loss: 0.6537 - Val Loss: 0.6876\n","Val Metrics: Precision=0.5914, Recall=0.5975, F1=0.5591\n","Epoch 15/30 - Train Loss: 0.6529 - Val Loss: 0.7114\n","Val Metrics: Precision=0.5898, Recall=0.5888, F1=0.5312\n","Epoch 16/30 - Train Loss: 0.6518 - Val Loss: 0.7030\n","Val Metrics: Precision=0.5898, Recall=0.5920, F1=0.5424\n","Epoch 17/30 - Train Loss: 0.6516 - Val Loss: 0.6576\n","Val Metrics: Precision=0.5908, Recall=0.5997, F1=0.5863\n","Epoch 18/30 - Train Loss: 0.6511 - Val Loss: 0.7048\n","Val Metrics: Precision=0.5878, Recall=0.5899, F1=0.5403\n","Epoch 19/30 - Train Loss: 0.6507 - Val Loss: 0.6647\n","Val Metrics: Precision=0.5925, Recall=0.6020, F1=0.5821\n","Epoch 20/30 - Train Loss: 0.6501 - Val Loss: 0.6668\n","Val Metrics: Precision=0.5904, Recall=0.5996, F1=0.5782\n","Epoch 21/30 - Train Loss: 0.6502 - Val Loss: 0.6842\n","Val Metrics: Precision=0.5947, Recall=0.6023, F1=0.5679\n","Epoch 22/30 - Train Loss: 0.6493 - Val Loss: 0.6956\n","Val Metrics: Precision=0.5883, Recall=0.5927, F1=0.5496\n","Epoch 23/30 - Train Loss: 0.6489 - Val Loss: 0.6966\n","Val Metrics: Precision=0.5888, Recall=0.5932, F1=0.5503\n","Epoch 24/30 - Train Loss: 0.6485 - Val Loss: 0.6627\n","Val Metrics: Precision=0.5939, Recall=0.6036, F1=0.5865\n","Epoch 25/30 - Train Loss: 0.6478 - Val Loss: 0.6965\n","Val Metrics: Precision=0.5899, Recall=0.5946, F1=0.5520\n","Epoch 26/30 - Train Loss: 0.6478 - Val Loss: 0.6790\n","Val Metrics: Precision=0.5933, Recall=0.6018, F1=0.5718\n","Epoch 27/30 - Train Loss: 0.6471 - Val Loss: 0.6926\n","Val Metrics: Precision=0.5873, Recall=0.5925, F1=0.5521\n","Epoch 28/30 - Train Loss: 0.6472 - Val Loss: 0.6819\n","Val Metrics: Precision=0.5952, Recall=0.6033, F1=0.5712\n","Epoch 29/30 - Train Loss: 0.6464 - Val Loss: 0.6905\n","Val Metrics: Precision=0.5891, Recall=0.5952, F1=0.5575\n","Epoch 30/30 - Train Loss: 0.6462 - Val Loss: 0.6890\n","Val Metrics: Precision=0.5929, Recall=0.6000, F1=0.5644\n","\n","Test Results:\n","Loss: 0.5909\n","Precision: 0.6172\n","Recall: 0.6355\n","F1 Score: 0.6234\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/av_fp_energy_efficiency_linear_model.pth\n","saved!\n","\n","\n","ablation: av_lst\n","Training data shape: (27922, 2051)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 2051)\n","Test data shape: (2756, 2051)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.6760 - Val Loss: 0.6759\n","Val Metrics: Precision=0.5913, Recall=0.6004, F1=0.5752\n","Epoch 2/30 - Train Loss: 0.6679 - Val Loss: 0.6702\n","Val Metrics: Precision=0.5948, Recall=0.6045, F1=0.5819\n","Epoch 3/30 - Train Loss: 0.6651 - Val Loss: 0.6588\n","Val Metrics: Precision=0.5938, Recall=0.6029, F1=0.5895\n","Epoch 4/30 - Train Loss: 0.6620 - Val Loss: 0.6495\n","Val Metrics: Precision=0.5945, Recall=0.6014, F1=0.5946\n","Epoch 5/30 - Train Loss: 0.6601 - Val Loss: 0.6609\n","Val Metrics: Precision=0.5982, Recall=0.6082, F1=0.5917\n","Epoch 6/30 - Train Loss: 0.6588 - Val Loss: 0.6556\n","Val Metrics: Precision=0.5992, Recall=0.6088, F1=0.5956\n","Epoch 7/30 - Train Loss: 0.6570 - Val Loss: 0.6503\n","Val Metrics: Precision=0.5984, Recall=0.6063, F1=0.5979\n","Epoch 8/30 - Train Loss: 0.6555 - Val Loss: 0.6758\n","Val Metrics: Precision=0.5971, Recall=0.6054, F1=0.5730\n","Epoch 9/30 - Train Loss: 0.6547 - Val Loss: 0.6623\n","Val Metrics: Precision=0.5969, Recall=0.6069, F1=0.5879\n","Epoch 10/30 - Train Loss: 0.6535 - Val Loss: 0.6635\n","Val Metrics: Precision=0.6005, Recall=0.6109, F1=0.5900\n","Epoch 11/30 - Train Loss: 0.6528 - Val Loss: 0.6710\n","Val Metrics: Precision=0.5992, Recall=0.6087, F1=0.5806\n","Epoch 12/30 - Train Loss: 0.6518 - Val Loss: 0.6710\n","Val Metrics: Precision=0.5983, Recall=0.6077, F1=0.5801\n","Epoch 13/30 - Train Loss: 0.6514 - Val Loss: 0.6618\n","Val Metrics: Precision=0.6013, Recall=0.6117, F1=0.5914\n","Epoch 14/30 - Train Loss: 0.6503 - Val Loss: 0.6535\n","Val Metrics: Precision=0.5948, Recall=0.6040, F1=0.5909\n","Epoch 15/30 - Train Loss: 0.6491 - Val Loss: 0.6323\n","Val Metrics: Precision=0.5918, Recall=0.5858, F1=0.5875\n","Epoch 16/30 - Train Loss: 0.6487 - Val Loss: 0.6647\n","Val Metrics: Precision=0.5979, Recall=0.6079, F1=0.5851\n","Epoch 17/30 - Train Loss: 0.6477 - Val Loss: 0.6468\n","Val Metrics: Precision=0.6009, Recall=0.6090, F1=0.6006\n","Epoch 18/30 - Train Loss: 0.6471 - Val Loss: 0.6530\n","Val Metrics: Precision=0.5961, Recall=0.6054, F1=0.5923\n","Epoch 19/30 - Train Loss: 0.6463 - Val Loss: 0.6714\n","Val Metrics: Precision=0.5973, Recall=0.6065, F1=0.5782\n","Epoch 20/30 - Train Loss: 0.6462 - Val Loss: 0.6610\n","Val Metrics: Precision=0.5958, Recall=0.6056, F1=0.5867\n","Epoch 21/30 - Train Loss: 0.6448 - Val Loss: 0.6714\n","Val Metrics: Precision=0.5964, Recall=0.6055, F1=0.5772\n","Epoch 22/30 - Train Loss: 0.6444 - Val Loss: 0.6545\n","Val Metrics: Precision=0.5960, Recall=0.6053, F1=0.5919\n","Epoch 23/30 - Train Loss: 0.6444 - Val Loss: 0.6718\n","Val Metrics: Precision=0.5993, Recall=0.6086, F1=0.5795\n","Epoch 24/30 - Train Loss: 0.6436 - Val Loss: 0.6613\n","Val Metrics: Precision=0.5934, Recall=0.6030, F1=0.5842\n","Epoch 25/30 - Train Loss: 0.6433 - Val Loss: 0.6568\n","Val Metrics: Precision=0.5971, Recall=0.6069, F1=0.5907\n","Epoch 26/30 - Train Loss: 0.6426 - Val Loss: 0.6538\n","Val Metrics: Precision=0.5954, Recall=0.6047, F1=0.5911\n","Epoch 27/30 - Train Loss: 0.6420 - Val Loss: 0.6671\n","Val Metrics: Precision=0.5961, Recall=0.6058, F1=0.5812\n","Epoch 28/30 - Train Loss: 0.6411 - Val Loss: 0.7022\n","Val Metrics: Precision=0.5980, Recall=0.5996, F1=0.5475\n","Epoch 29/30 - Train Loss: 0.6412 - Val Loss: 0.6434\n","Val Metrics: Precision=0.5992, Recall=0.6053, F1=0.6001\n","Epoch 30/30 - Train Loss: 0.6404 - Val Loss: 0.6504\n","Val Metrics: Precision=0.5947, Recall=0.6031, F1=0.5930\n","\n","Test Results:\n","Loss: 0.5738\n","Precision: 0.6282\n","Recall: 0.6343\n","F1 Score: 0.6309\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/av_lst_energy_efficiency_linear_model.pth\n","saved!\n","\n","\n","ablation: av_sv\n","Training data shape: (27922, 4096)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 4096)\n","Test data shape: (2756, 4096)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.6696 - Val Loss: 0.6656\n","Val Metrics: Precision=0.6031, Recall=0.6133, F1=0.5878\n","Epoch 2/30 - Train Loss: 0.6572 - Val Loss: 0.6716\n","Val Metrics: Precision=0.6097, Recall=0.6190, F1=0.5853\n","Epoch 3/30 - Train Loss: 0.6526 - Val Loss: 0.6583\n","Val Metrics: Precision=0.6090, Recall=0.6203, F1=0.6001\n","Epoch 4/30 - Train Loss: 0.6482 - Val Loss: 0.6964\n","Val Metrics: Precision=0.6212, Recall=0.6239, F1=0.5710\n","Epoch 5/30 - Train Loss: 0.6464 - Val Loss: 0.6708\n","Val Metrics: Precision=0.6101, Recall=0.6203, F1=0.5904\n","Epoch 6/30 - Train Loss: 0.6436 - Val Loss: 0.6473\n","Val Metrics: Precision=0.6090, Recall=0.6191, F1=0.6069\n","Epoch 7/30 - Train Loss: 0.6409 - Val Loss: 0.6189\n","Val Metrics: Precision=0.6047, Recall=0.5943, F1=0.5966\n","Epoch 8/30 - Train Loss: 0.6400 - Val Loss: 0.6245\n","Val Metrics: Precision=0.5985, Recall=0.5969, F1=0.5976\n","Epoch 9/30 - Train Loss: 0.6377 - Val Loss: 0.6746\n","Val Metrics: Precision=0.6110, Recall=0.6208, F1=0.5881\n","Epoch 10/30 - Train Loss: 0.6355 - Val Loss: 0.6850\n","Val Metrics: Precision=0.6133, Recall=0.6216, F1=0.5833\n","Epoch 11/30 - Train Loss: 0.6345 - Val Loss: 0.6564\n","Val Metrics: Precision=0.6116, Recall=0.6230, F1=0.6047\n","Epoch 12/30 - Train Loss: 0.6327 - Val Loss: 0.6463\n","Val Metrics: Precision=0.6076, Recall=0.6173, F1=0.6058\n","Epoch 13/30 - Train Loss: 0.6332 - Val Loss: 0.6217\n","Val Metrics: Precision=0.6001, Recall=0.5961, F1=0.5975\n","Epoch 14/30 - Train Loss: 0.6310 - Val Loss: 0.6444\n","Val Metrics: Precision=0.6080, Recall=0.6170, F1=0.6075\n","Epoch 15/30 - Train Loss: 0.6302 - Val Loss: 0.6555\n","Val Metrics: Precision=0.6155, Recall=0.6273, F1=0.6094\n","Epoch 16/30 - Train Loss: 0.6288 - Val Loss: 0.6883\n","Val Metrics: Precision=0.6125, Recall=0.6204, F1=0.5810\n","Epoch 17/30 - Train Loss: 0.6276 - Val Loss: 0.6418\n","Val Metrics: Precision=0.6021, Recall=0.6100, F1=0.6022\n","Epoch 18/30 - Train Loss: 0.6278 - Val Loss: 0.6516\n","Val Metrics: Precision=0.6118, Recall=0.6228, F1=0.6079\n","Epoch 19/30 - Train Loss: 0.6256 - Val Loss: 0.6607\n","Val Metrics: Precision=0.6155, Recall=0.6274, F1=0.6053\n","Epoch 20/30 - Train Loss: 0.6254 - Val Loss: 0.6705\n","Val Metrics: Precision=0.6126, Recall=0.6236, F1=0.5961\n","Epoch 21/30 - Train Loss: 0.6245 - Val Loss: 0.6421\n","Val Metrics: Precision=0.6027, Recall=0.6109, F1=0.6026\n","Epoch 22/30 - Train Loss: 0.6236 - Val Loss: 0.6468\n","Val Metrics: Precision=0.6049, Recall=0.6143, F1=0.6034\n","Epoch 23/30 - Train Loss: 0.6228 - Val Loss: 0.6390\n","Val Metrics: Precision=0.6037, Recall=0.6102, F1=0.6047\n","Epoch 24/30 - Train Loss: 0.6213 - Val Loss: 0.6271\n","Val Metrics: Precision=0.5965, Recall=0.5957, F1=0.5961\n","Epoch 25/30 - Train Loss: 0.6212 - Val Loss: 0.6469\n","Val Metrics: Precision=0.6033, Recall=0.6125, F1=0.6018\n","Epoch 26/30 - Train Loss: 0.6202 - Val Loss: 0.6590\n","Val Metrics: Precision=0.6112, Recall=0.6226, F1=0.6037\n","Epoch 27/30 - Train Loss: 0.6203 - Val Loss: 0.6433\n","Val Metrics: Precision=0.6060, Recall=0.6142, F1=0.6063\n","Epoch 28/30 - Train Loss: 0.6193 - Val Loss: 0.6453\n","Val Metrics: Precision=0.6022, Recall=0.6109, F1=0.6013\n","Epoch 29/30 - Train Loss: 0.6180 - Val Loss: 0.6778\n","Val Metrics: Precision=0.6120, Recall=0.6224, F1=0.5922\n","Epoch 30/30 - Train Loss: 0.6182 - Val Loss: 0.6554\n","Val Metrics: Precision=0.6113, Recall=0.6225, F1=0.6060\n","\n","Test Results:\n","Loss: 0.5083\n","Precision: 0.6608\n","Recall: 0.6253\n","F1 Score: 0.6370\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/av_sv_energy_efficiency_linear_model.pth\n","saved!\n","\n","\n","ablation: sv_fp\n","Training data shape: (27922, 2049)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 2049)\n","Test data shape: (2756, 2049)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.6833 - Val Loss: 0.7231\n","Val Metrics: Precision=0.5803, Recall=0.5629, F1=0.4677\n","Epoch 2/30 - Train Loss: 0.6700 - Val Loss: 0.6697\n","Val Metrics: Precision=0.5928, Recall=0.6023, F1=0.5853\n","Epoch 3/30 - Train Loss: 0.6649 - Val Loss: 0.6768\n","Val Metrics: Precision=0.5978, Recall=0.6073, F1=0.5804\n","Epoch 4/30 - Train Loss: 0.6628 - Val Loss: 0.6779\n","Val Metrics: Precision=0.5966, Recall=0.6058, F1=0.5780\n","Epoch 5/30 - Train Loss: 0.6608 - Val Loss: 0.6727\n","Val Metrics: Precision=0.5995, Recall=0.6095, F1=0.5852\n","Epoch 6/30 - Train Loss: 0.6586 - Val Loss: 0.6742\n","Val Metrics: Precision=0.6007, Recall=0.6106, F1=0.5851\n","Epoch 7/30 - Train Loss: 0.6575 - Val Loss: 0.6552\n","Val Metrics: Precision=0.5956, Recall=0.6036, F1=0.5948\n","Epoch 8/30 - Train Loss: 0.6562 - Val Loss: 0.6450\n","Val Metrics: Precision=0.5833, Recall=0.5860, F1=0.5842\n","Epoch 9/30 - Train Loss: 0.6554 - Val Loss: 0.6455\n","Val Metrics: Precision=0.5905, Recall=0.5940, F1=0.5916\n","Epoch 10/30 - Train Loss: 0.6537 - Val Loss: 0.6788\n","Val Metrics: Precision=0.6001, Recall=0.6091, F1=0.5784\n","Epoch 11/30 - Train Loss: 0.6532 - Val Loss: 0.6507\n","Val Metrics: Precision=0.5949, Recall=0.6021, F1=0.5948\n","Epoch 12/30 - Train Loss: 0.6524 - Val Loss: 0.6844\n","Val Metrics: Precision=0.5989, Recall=0.6061, F1=0.5690\n","Epoch 13/30 - Train Loss: 0.6506 - Val Loss: 0.6696\n","Val Metrics: Precision=0.5980, Recall=0.6080, F1=0.5856\n","Epoch 14/30 - Train Loss: 0.6504 - Val Loss: 0.6490\n","Val Metrics: Precision=0.5950, Recall=0.6022, F1=0.5950\n","Epoch 15/30 - Train Loss: 0.6502 - Val Loss: 0.6571\n","Val Metrics: Precision=0.5995, Recall=0.6089, F1=0.5964\n","Epoch 16/30 - Train Loss: 0.6492 - Val Loss: 0.6544\n","Val Metrics: Precision=0.6024, Recall=0.6120, F1=0.6000\n","Epoch 17/30 - Train Loss: 0.6486 - Val Loss: 0.6371\n","Val Metrics: Precision=0.5928, Recall=0.5925, F1=0.5926\n","Epoch 18/30 - Train Loss: 0.6478 - Val Loss: 0.6528\n","Val Metrics: Precision=0.5971, Recall=0.6055, F1=0.5958\n","Epoch 19/30 - Train Loss: 0.6474 - Val Loss: 0.6422\n","Val Metrics: Precision=0.5940, Recall=0.5979, F1=0.5952\n","Epoch 20/30 - Train Loss: 0.6471 - Val Loss: 0.6298\n","Val Metrics: Precision=0.5830, Recall=0.5764, F1=0.5778\n","Epoch 21/30 - Train Loss: 0.6459 - Val Loss: 0.6194\n","Val Metrics: Precision=0.5869, Recall=0.5626, F1=0.5585\n","Epoch 22/30 - Train Loss: 0.6463 - Val Loss: 0.6314\n","Val Metrics: Precision=0.5891, Recall=0.5847, F1=0.5861\n","Epoch 23/30 - Train Loss: 0.6454 - Val Loss: 0.6380\n","Val Metrics: Precision=0.5931, Recall=0.5942, F1=0.5936\n","Epoch 24/30 - Train Loss: 0.6446 - Val Loss: 0.6246\n","Val Metrics: Precision=0.5880, Recall=0.5753, F1=0.5763\n","Epoch 25/30 - Train Loss: 0.6444 - Val Loss: 0.6225\n","Val Metrics: Precision=0.5849, Recall=0.5688, F1=0.5685\n","Epoch 26/30 - Train Loss: 0.6438 - Val Loss: 0.6271\n","Val Metrics: Precision=0.5899, Recall=0.5818, F1=0.5835\n","Epoch 27/30 - Train Loss: 0.6436 - Val Loss: 0.6285\n","Val Metrics: Precision=0.5914, Recall=0.5844, F1=0.5862\n","Epoch 28/30 - Train Loss: 0.6427 - Val Loss: 0.6419\n","Val Metrics: Precision=0.5927, Recall=0.5971, F1=0.5938\n","Epoch 29/30 - Train Loss: 0.6428 - Val Loss: 0.6320\n","Val Metrics: Precision=0.5929, Recall=0.5899, F1=0.5910\n","Epoch 30/30 - Train Loss: 0.6428 - Val Loss: 0.6235\n","Val Metrics: Precision=0.5928, Recall=0.5774, F1=0.5783\n","\n","Test Results:\n","Loss: 0.5013\n","Precision: 0.6640\n","Recall: 0.5521\n","F1 Score: 0.5474\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/sv_fp_energy_efficiency_linear_model.pth\n","saved!\n","\n","\n","ablation: sv_lst\n","Training data shape: (27922, 2051)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 2051)\n","Test data shape: (2756, 2051)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.6803 - Val Loss: 0.6712\n","Val Metrics: Precision=0.5776, Recall=0.5855, F1=0.5710\n","Epoch 2/30 - Train Loss: 0.6682 - Val Loss: 0.6456\n","Val Metrics: Precision=0.5776, Recall=0.5752, F1=0.5761\n","Epoch 3/30 - Train Loss: 0.6643 - Val Loss: 0.6561\n","Val Metrics: Precision=0.5919, Recall=0.5991, F1=0.5915\n","Epoch 4/30 - Train Loss: 0.6605 - Val Loss: 0.6681\n","Val Metrics: Precision=0.5952, Recall=0.6050, F1=0.5841\n","Epoch 5/30 - Train Loss: 0.6589 - Val Loss: 0.6988\n","Val Metrics: Precision=0.5966, Recall=0.5970, F1=0.5422\n","Epoch 6/30 - Train Loss: 0.6570 - Val Loss: 0.6553\n","Val Metrics: Precision=0.5960, Recall=0.6047, F1=0.5937\n","Epoch 7/30 - Train Loss: 0.6554 - Val Loss: 0.7101\n","Val Metrics: Precision=0.5987, Recall=0.5928, F1=0.5248\n","Epoch 8/30 - Train Loss: 0.6544 - Val Loss: 0.6596\n","Val Metrics: Precision=0.6009, Recall=0.6111, F1=0.5949\n","Epoch 9/30 - Train Loss: 0.6520 - Val Loss: 0.6516\n","Val Metrics: Precision=0.5940, Recall=0.6020, F1=0.5929\n","Epoch 10/30 - Train Loss: 0.6514 - Val Loss: 0.6396\n","Val Metrics: Precision=0.5991, Recall=0.6013, F1=0.6000\n","Epoch 11/30 - Train Loss: 0.6503 - Val Loss: 0.6907\n","Val Metrics: Precision=0.6013, Recall=0.6059, F1=0.5605\n","Epoch 12/30 - Train Loss: 0.6495 - Val Loss: 0.6564\n","Val Metrics: Precision=0.6029, Recall=0.6130, F1=0.5985\n","Epoch 13/30 - Train Loss: 0.6484 - Val Loss: 0.6565\n","Val Metrics: Precision=0.6014, Recall=0.6116, F1=0.5963\n","Epoch 14/30 - Train Loss: 0.6474 - Val Loss: 0.6644\n","Val Metrics: Precision=0.6036, Recall=0.6143, F1=0.5932\n","Epoch 15/30 - Train Loss: 0.6465 - Val Loss: 0.6689\n","Val Metrics: Precision=0.6026, Recall=0.6129, F1=0.5879\n","Epoch 16/30 - Train Loss: 0.6460 - Val Loss: 0.6515\n","Val Metrics: Precision=0.6005, Recall=0.6097, F1=0.5983\n","Epoch 17/30 - Train Loss: 0.6454 - Val Loss: 0.6593\n","Val Metrics: Precision=0.6063, Recall=0.6172, F1=0.5991\n","Epoch 18/30 - Train Loss: 0.6445 - Val Loss: 0.6603\n","Val Metrics: Precision=0.6055, Recall=0.6163, F1=0.5981\n","Epoch 19/30 - Train Loss: 0.6438 - Val Loss: 0.6855\n","Val Metrics: Precision=0.6031, Recall=0.6097, F1=0.5696\n","Epoch 20/30 - Train Loss: 0.6431 - Val Loss: 0.6391\n","Val Metrics: Precision=0.5967, Recall=0.6005, F1=0.5979\n","Epoch 21/30 - Train Loss: 0.6423 - Val Loss: 0.6499\n","Val Metrics: Precision=0.6042, Recall=0.6135, F1=0.6027\n","Epoch 22/30 - Train Loss: 0.6419 - Val Loss: 0.6609\n","Val Metrics: Precision=0.6068, Recall=0.6178, F1=0.5987\n","Epoch 23/30 - Train Loss: 0.6410 - Val Loss: 0.6483\n","Val Metrics: Precision=0.6032, Recall=0.6121, F1=0.6021\n","Epoch 24/30 - Train Loss: 0.6405 - Val Loss: 0.6564\n","Val Metrics: Precision=0.6066, Recall=0.6174, F1=0.6004\n","Epoch 25/30 - Train Loss: 0.6393 - Val Loss: 0.6381\n","Val Metrics: Precision=0.5955, Recall=0.5998, F1=0.5966\n","Epoch 26/30 - Train Loss: 0.6389 - Val Loss: 0.6382\n","Val Metrics: Precision=0.5953, Recall=0.5998, F1=0.5965\n","Epoch 27/30 - Train Loss: 0.6389 - Val Loss: 0.6360\n","Val Metrics: Precision=0.5975, Recall=0.6013, F1=0.5987\n","Epoch 28/30 - Train Loss: 0.6379 - Val Loss: 0.6652\n","Val Metrics: Precision=0.6058, Recall=0.6166, F1=0.5936\n","Epoch 29/30 - Train Loss: 0.6384 - Val Loss: 0.6234\n","Val Metrics: Precision=0.6002, Recall=0.5919, F1=0.5940\n","Epoch 30/30 - Train Loss: 0.6371 - Val Loss: 0.6361\n","Val Metrics: Precision=0.5970, Recall=0.6006, F1=0.5982\n","\n","Test Results:\n","Loss: 0.4999\n","Precision: 0.6737\n","Recall: 0.5730\n","F1 Score: 0.5791\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/sv_lst_energy_efficiency_linear_model.pth\n","saved!\n","\n","\n","ablation: lst_fp\n","Training data shape: (27922, 4)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 4)\n","Test data shape: (2756, 4)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 7.0953 - Val Loss: 0.6624\n","Val Metrics: Precision=0.5764, Recall=0.5002, F1=0.3959\n","Epoch 2/30 - Train Loss: 0.6959 - Val Loss: 0.6505\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 3/30 - Train Loss: 0.6947 - Val Loss: 0.6499\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 4/30 - Train Loss: 0.6944 - Val Loss: 0.6485\n","Val Metrics: Precision=0.3264, Recall=0.5000, F1=0.3950\n","Epoch 5/30 - Train Loss: 0.6944 - Val Loss: 0.6501\n","Val Metrics: Precision=0.3263, Recall=0.4997, F1=0.3948\n","Epoch 6/30 - Train Loss: 0.6939 - Val Loss: 0.6511\n","Val Metrics: Precision=0.5764, Recall=0.5002, F1=0.3959\n","Epoch 7/30 - Train Loss: 0.6936 - Val Loss: 0.6481\n","Val Metrics: Precision=0.3263, Recall=0.4997, F1=0.3948\n","Epoch 8/30 - Train Loss: 0.6931 - Val Loss: 0.6505\n","Val Metrics: Precision=0.5764, Recall=0.5002, F1=0.3959\n","Epoch 9/30 - Train Loss: 0.6929 - Val Loss: 0.6485\n","Val Metrics: Precision=0.5764, Recall=0.5002, F1=0.3959\n","Epoch 10/30 - Train Loss: 0.6927 - Val Loss: 0.6492\n","Val Metrics: Precision=0.5764, Recall=0.5002, F1=0.3959\n","Epoch 11/30 - Train Loss: 0.6922 - Val Loss: 0.6501\n","Val Metrics: Precision=0.5764, Recall=0.5002, F1=0.3959\n","Epoch 12/30 - Train Loss: 0.6922 - Val Loss: 0.6499\n","Val Metrics: Precision=0.5764, Recall=0.5002, F1=0.3959\n","Epoch 13/30 - Train Loss: 0.6919 - Val Loss: 0.6480\n","Val Metrics: Precision=0.5764, Recall=0.5002, F1=0.3959\n","Epoch 14/30 - Train Loss: 0.6915 - Val Loss: 0.6509\n","Val Metrics: Precision=0.6599, Recall=0.5008, F1=0.3970\n","Epoch 15/30 - Train Loss: 0.6913 - Val Loss: 0.6507\n","Val Metrics: Precision=0.6599, Recall=0.5008, F1=0.3970\n","Epoch 16/30 - Train Loss: 0.6907 - Val Loss: 0.6474\n","Val Metrics: Precision=0.5764, Recall=0.5002, F1=0.3959\n","Epoch 17/30 - Train Loss: 0.6907 - Val Loss: 0.6492\n","Val Metrics: Precision=0.6599, Recall=0.5008, F1=0.3970\n","Epoch 18/30 - Train Loss: 0.6902 - Val Loss: 0.6501\n","Val Metrics: Precision=0.6266, Recall=0.5010, F1=0.3980\n","Epoch 19/30 - Train Loss: 0.6899 - Val Loss: 0.6475\n","Val Metrics: Precision=0.7017, Recall=0.5013, F1=0.3981\n","Epoch 20/30 - Train Loss: 0.6897 - Val Loss: 0.6479\n","Val Metrics: Precision=0.6266, Recall=0.5010, F1=0.3980\n","Epoch 21/30 - Train Loss: 0.6898 - Val Loss: 0.6475\n","Val Metrics: Precision=0.6393, Recall=0.5017, F1=0.4001\n","Epoch 22/30 - Train Loss: 0.6892 - Val Loss: 0.6462\n","Val Metrics: Precision=0.6393, Recall=0.5017, F1=0.4001\n","Epoch 23/30 - Train Loss: 0.6889 - Val Loss: 0.6479\n","Val Metrics: Precision=0.6045, Recall=0.5015, F1=0.3999\n","Epoch 24/30 - Train Loss: 0.6888 - Val Loss: 0.6473\n","Val Metrics: Precision=0.5767, Recall=0.5012, F1=0.3998\n","Epoch 25/30 - Train Loss: 0.6886 - Val Loss: 0.6470\n","Val Metrics: Precision=0.5767, Recall=0.5012, F1=0.3998\n","Epoch 26/30 - Train Loss: 0.6882 - Val Loss: 0.6476\n","Val Metrics: Precision=0.6048, Recall=0.5029, F1=0.4048\n","Epoch 27/30 - Train Loss: 0.6880 - Val Loss: 0.6451\n","Val Metrics: Precision=0.6186, Recall=0.5022, F1=0.4020\n","Epoch 28/30 - Train Loss: 0.6878 - Val Loss: 0.6467\n","Val Metrics: Precision=0.6369, Recall=0.5045, F1=0.4081\n","Epoch 29/30 - Train Loss: 0.6872 - Val Loss: 0.6457\n","Val Metrics: Precision=0.6369, Recall=0.5045, F1=0.4081\n","Epoch 30/30 - Train Loss: 0.6873 - Val Loss: 0.6476\n","Val Metrics: Precision=0.6426, Recall=0.5060, F1=0.4121\n","\n","Test Results:\n","Loss: 0.7235\n","Precision: 0.6103\n","Recall: 0.5042\n","F1 Score: 0.1890\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/lst_fp_energy_efficiency_linear_model.pth\n","saved!\n","\n","\n"]}]},{"cell_type":"code","source":["# set device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","ablations = ['av_lst_fp', 'av_sv_lst', 'av_sv_fp', 'sv_lst_fp']\n","for ablation in ablations:\n","  print(f\"ablation: {ablation}\")\n","  # get data and loaders\n","  data_loader_dict = get_loaders(ablation)\n","\n","  train_loader, val_loader, test_loader = data_loader_dict['loaders']\n","  X_train, y_train = data_loader_dict['data']\n","\n","  # input dim\n","  input_dim = X_train.shape[1]\n","\n","  # train model\n","  model, test_metrics = train_linear_model(train_loader, val_loader, test_loader, input_dim, device)\n","\n","  # model path\n","  model_path = '/content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/' + ablation + '_energy_efficiency_linear_model.pth'\n","  print(f\"path: {model_path}\")\n","\n","  # save trained model\n","  torch.save(model.state_dict(), model_path)\n","  print(f\"saved!\\n\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V90YG_KRgz1E","executionInfo":{"status":"ok","timestamp":1745963494875,"user_tz":240,"elapsed":335363,"user":{"displayName":"Eric Zheng","userId":"09751706780638879012"}},"outputId":"6b6481ca-3d2e-4d4a-8081-b709e04ae25e"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Using device: cpu\n","ablation: av_lst_fp\n","Training data shape: (27922, 2052)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 2052)\n","Test data shape: (2756, 2052)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.6879 - Val Loss: 1.0184\n","Val Metrics: Precision=0.1736, Recall=0.5000, F1=0.2577\n","Epoch 2/30 - Train Loss: 0.6704 - Val Loss: 0.8622\n","Val Metrics: Precision=0.5909, Recall=0.5208, F1=0.3252\n","Epoch 3/30 - Train Loss: 0.6669 - Val Loss: 0.8843\n","Val Metrics: Precision=0.5790, Recall=0.5168, F1=0.3179\n","Epoch 4/30 - Train Loss: 0.6630 - Val Loss: 0.7845\n","Val Metrics: Precision=0.6028, Recall=0.5619, F1=0.4339\n","Epoch 5/30 - Train Loss: 0.6614 - Val Loss: 0.7823\n","Val Metrics: Precision=0.6028, Recall=0.5669, F1=0.4472\n","Epoch 6/30 - Train Loss: 0.6596 - Val Loss: 0.7505\n","Val Metrics: Precision=0.6009, Recall=0.5813, F1=0.4887\n","Epoch 7/30 - Train Loss: 0.6576 - Val Loss: 0.7430\n","Val Metrics: Precision=0.6042, Recall=0.5872, F1=0.4998\n","Epoch 8/30 - Train Loss: 0.6566 - Val Loss: 0.7905\n","Val Metrics: Precision=0.6102, Recall=0.5695, F1=0.4463\n","Epoch 9/30 - Train Loss: 0.6554 - Val Loss: 0.7764\n","Val Metrics: Precision=0.6081, Recall=0.5741, F1=0.4601\n","Epoch 10/30 - Train Loss: 0.6541 - Val Loss: 0.7431\n","Val Metrics: Precision=0.5993, Recall=0.5846, F1=0.5001\n","Epoch 11/30 - Train Loss: 0.6532 - Val Loss: 0.7532\n","Val Metrics: Precision=0.6038, Recall=0.5819, F1=0.4860\n","Epoch 12/30 - Train Loss: 0.6530 - Val Loss: 0.7895\n","Val Metrics: Precision=0.6007, Recall=0.5632, F1=0.4398\n","Epoch 13/30 - Train Loss: 0.6515 - Val Loss: 0.7168\n","Val Metrics: Precision=0.5976, Recall=0.5930, F1=0.5275\n","Epoch 14/30 - Train Loss: 0.6510 - Val Loss: 0.6973\n","Val Metrics: Precision=0.5970, Recall=0.6004, F1=0.5526\n","Epoch 15/30 - Train Loss: 0.6496 - Val Loss: 0.6966\n","Val Metrics: Precision=0.5951, Recall=0.5982, F1=0.5501\n","Epoch 16/30 - Train Loss: 0.6484 - Val Loss: 0.7575\n","Val Metrics: Precision=0.6071, Recall=0.5869, F1=0.4947\n","Epoch 17/30 - Train Loss: 0.6481 - Val Loss: 0.6892\n","Val Metrics: Precision=0.5991, Recall=0.6051, F1=0.5641\n","Epoch 18/30 - Train Loss: 0.6475 - Val Loss: 0.7117\n","Val Metrics: Precision=0.5949, Recall=0.5937, F1=0.5354\n","Epoch 19/30 - Train Loss: 0.6466 - Val Loss: 0.7143\n","Val Metrics: Precision=0.6023, Recall=0.6001, F1=0.5393\n","Epoch 20/30 - Train Loss: 0.6474 - Val Loss: 0.7197\n","Val Metrics: Precision=0.5986, Recall=0.5944, F1=0.5297\n","Epoch 21/30 - Train Loss: 0.6455 - Val Loss: 0.7426\n","Val Metrics: Precision=0.6050, Recall=0.5908, F1=0.5081\n","Epoch 22/30 - Train Loss: 0.6447 - Val Loss: 0.7182\n","Val Metrics: Precision=0.6039, Recall=0.5997, F1=0.5351\n","Epoch 23/30 - Train Loss: 0.6446 - Val Loss: 0.7078\n","Val Metrics: Precision=0.5986, Recall=0.5984, F1=0.5422\n","Epoch 24/30 - Train Loss: 0.6439 - Val Loss: 0.7356\n","Val Metrics: Precision=0.6059, Recall=0.5959, F1=0.5206\n","Epoch 25/30 - Train Loss: 0.6439 - Val Loss: 0.7009\n","Val Metrics: Precision=0.5971, Recall=0.5993, F1=0.5485\n","Epoch 26/30 - Train Loss: 0.6424 - Val Loss: 0.6602\n","Val Metrics: Precision=0.5991, Recall=0.6093, F1=0.5900\n","Epoch 27/30 - Train Loss: 0.6419 - Val Loss: 0.6713\n","Val Metrics: Precision=0.6018, Recall=0.6118, F1=0.5847\n","Epoch 28/30 - Train Loss: 0.6417 - Val Loss: 0.6846\n","Val Metrics: Precision=0.5984, Recall=0.6052, F1=0.5665\n","Epoch 29/30 - Train Loss: 0.6409 - Val Loss: 0.7008\n","Val Metrics: Precision=0.5933, Recall=0.5960, F1=0.5473\n","Epoch 30/30 - Train Loss: 0.6406 - Val Loss: 0.7047\n","Val Metrics: Precision=0.5997, Recall=0.6015, F1=0.5496\n","\n","Test Results:\n","Loss: 0.5926\n","Precision: 0.6168\n","Recall: 0.6399\n","F1 Score: 0.6234\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/av_lst_fp_energy_efficiency_linear_model.pth\n","saved!\n","\n","\n","ablation: av_sv_lst\n","Training data shape: (27922, 4099)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 4099)\n","Test data shape: (2756, 4099)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.6709 - Val Loss: 0.6755\n","Val Metrics: Precision=0.6097, Recall=0.6190, F1=0.5850\n","Epoch 2/30 - Train Loss: 0.6573 - Val Loss: 0.6728\n","Val Metrics: Precision=0.6101, Recall=0.6191, F1=0.5842\n","Epoch 3/30 - Train Loss: 0.6523 - Val Loss: 0.6811\n","Val Metrics: Precision=0.6111, Recall=0.6184, F1=0.5778\n","Epoch 4/30 - Train Loss: 0.6482 - Val Loss: 0.6678\n","Val Metrics: Precision=0.6108, Recall=0.6211, F1=0.5908\n","Epoch 5/30 - Train Loss: 0.6458 - Val Loss: 0.6302\n","Val Metrics: Precision=0.6003, Recall=0.6032, F1=0.6014\n","Epoch 6/30 - Train Loss: 0.6427 - Val Loss: 0.6430\n","Val Metrics: Precision=0.6081, Recall=0.6174, F1=0.6072\n","Epoch 7/30 - Train Loss: 0.6411 - Val Loss: 0.6898\n","Val Metrics: Precision=0.6065, Recall=0.6122, F1=0.5684\n","Epoch 8/30 - Train Loss: 0.6381 - Val Loss: 0.6755\n","Val Metrics: Precision=0.6092, Recall=0.6185, F1=0.5849\n","Epoch 9/30 - Train Loss: 0.6363 - Val Loss: 0.6597\n","Val Metrics: Precision=0.6190, Recall=0.6312, F1=0.6082\n","Epoch 10/30 - Train Loss: 0.6346 - Val Loss: 0.6593\n","Val Metrics: Precision=0.6159, Recall=0.6279, F1=0.6055\n","Epoch 11/30 - Train Loss: 0.6334 - Val Loss: 0.7196\n","Val Metrics: Precision=0.6188, Recall=0.6164, F1=0.5543\n","Epoch 12/30 - Train Loss: 0.6318 - Val Loss: 0.6414\n","Val Metrics: Precision=0.6034, Recall=0.6120, F1=0.6029\n","Epoch 13/30 - Train Loss: 0.6308 - Val Loss: 0.6200\n","Val Metrics: Precision=0.5910, Recall=0.5870, F1=0.5884\n","Epoch 14/30 - Train Loss: 0.6288 - Val Loss: 0.6659\n","Val Metrics: Precision=0.6152, Recall=0.6267, F1=0.6007\n","Epoch 15/30 - Train Loss: 0.6274 - Val Loss: 0.6569\n","Val Metrics: Precision=0.6173, Recall=0.6294, F1=0.6085\n","Epoch 16/30 - Train Loss: 0.6270 - Val Loss: 0.6729\n","Val Metrics: Precision=0.6175, Recall=0.6285, F1=0.5982\n","Epoch 17/30 - Train Loss: 0.6255 - Val Loss: 0.6413\n","Val Metrics: Precision=0.6043, Recall=0.6131, F1=0.6038\n","Epoch 18/30 - Train Loss: 0.6252 - Val Loss: 0.6392\n","Val Metrics: Precision=0.6069, Recall=0.6154, F1=0.6070\n","Epoch 19/30 - Train Loss: 0.6236 - Val Loss: 0.6993\n","Val Metrics: Precision=0.6169, Recall=0.6218, F1=0.5741\n","Epoch 20/30 - Train Loss: 0.6219 - Val Loss: 0.6262\n","Val Metrics: Precision=0.5983, Recall=0.5994, F1=0.5988\n","Epoch 21/30 - Train Loss: 0.6217 - Val Loss: 0.6357\n","Val Metrics: Precision=0.6007, Recall=0.6067, F1=0.6018\n","Epoch 22/30 - Train Loss: 0.6214 - Val Loss: 0.6582\n","Val Metrics: Precision=0.6147, Recall=0.6265, F1=0.6059\n","Epoch 23/30 - Train Loss: 0.6189 - Val Loss: 0.6156\n","Val Metrics: Precision=0.6000, Recall=0.5896, F1=0.5917\n","Epoch 24/30 - Train Loss: 0.6183 - Val Loss: 0.6263\n","Val Metrics: Precision=0.5960, Recall=0.5971, F1=0.5965\n","Epoch 25/30 - Train Loss: 0.6172 - Val Loss: 0.6509\n","Val Metrics: Precision=0.6097, Recall=0.6204, F1=0.6056\n","Epoch 26/30 - Train Loss: 0.6170 - Val Loss: 0.6396\n","Val Metrics: Precision=0.6057, Recall=0.6142, F1=0.6055\n","Epoch 27/30 - Train Loss: 0.6161 - Val Loss: 0.6385\n","Val Metrics: Precision=0.6067, Recall=0.6146, F1=0.6073\n","Epoch 28/30 - Train Loss: 0.6154 - Val Loss: 0.6618\n","Val Metrics: Precision=0.6152, Recall=0.6271, F1=0.6050\n","Epoch 29/30 - Train Loss: 0.6153 - Val Loss: 0.6353\n","Val Metrics: Precision=0.6049, Recall=0.6118, F1=0.6059\n","Epoch 30/30 - Train Loss: 0.6144 - Val Loss: 0.6954\n","Val Metrics: Precision=0.6190, Recall=0.6264, F1=0.5840\n","\n","Test Results:\n","Loss: 0.5474\n","Precision: 0.6552\n","Recall: 0.6755\n","F1 Score: 0.6630\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/av_sv_lst_energy_efficiency_linear_model.pth\n","saved!\n","\n","\n","ablation: av_sv_fp\n","Training data shape: (27922, 4097)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 4097)\n","Test data shape: (2756, 4097)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.6760 - Val Loss: 0.6485\n","Val Metrics: Precision=0.5082, Recall=0.5001, F1=0.3984\n","Epoch 2/30 - Train Loss: 0.6588 - Val Loss: 0.6397\n","Val Metrics: Precision=0.6132, Recall=0.5049, F1=0.4107\n","Epoch 3/30 - Train Loss: 0.6530 - Val Loss: 0.6127\n","Val Metrics: Precision=0.6012, Recall=0.5501, F1=0.5296\n","Epoch 4/30 - Train Loss: 0.6506 - Val Loss: 0.6204\n","Val Metrics: Precision=0.5917, Recall=0.5146, F1=0.4440\n","Epoch 5/30 - Train Loss: 0.6468 - Val Loss: 0.6115\n","Val Metrics: Precision=0.6035, Recall=0.5650, F1=0.5566\n","Epoch 6/30 - Train Loss: 0.6437 - Val Loss: 0.6120\n","Val Metrics: Precision=0.5958, Recall=0.5393, F1=0.5086\n","Epoch 7/30 - Train Loss: 0.6422 - Val Loss: 0.6133\n","Val Metrics: Precision=0.6011, Recall=0.5378, F1=0.5029\n","Epoch 8/30 - Train Loss: 0.6393 - Val Loss: 0.6206\n","Val Metrics: Precision=0.5953, Recall=0.5202, F1=0.4597\n","Epoch 9/30 - Train Loss: 0.6388 - Val Loss: 0.6116\n","Val Metrics: Precision=0.6046, Recall=0.5478, F1=0.5237\n","Epoch 10/30 - Train Loss: 0.6366 - Val Loss: 0.6216\n","Val Metrics: Precision=0.5990, Recall=0.5931, F1=0.5949\n","Epoch 11/30 - Train Loss: 0.6354 - Val Loss: 0.6109\n","Val Metrics: Precision=0.5950, Recall=0.5543, F1=0.5405\n","Epoch 12/30 - Train Loss: 0.6345 - Val Loss: 0.6261\n","Val Metrics: Precision=0.6075, Recall=0.5199, F1=0.4555\n","Epoch 13/30 - Train Loss: 0.6335 - Val Loss: 0.6216\n","Val Metrics: Precision=0.6016, Recall=0.5286, F1=0.4803\n","Epoch 14/30 - Train Loss: 0.6317 - Val Loss: 0.6214\n","Val Metrics: Precision=0.5936, Recall=0.5245, F1=0.4724\n","Epoch 15/30 - Train Loss: 0.6303 - Val Loss: 0.6120\n","Val Metrics: Precision=0.5964, Recall=0.5648, F1=0.5587\n","Epoch 16/30 - Train Loss: 0.6300 - Val Loss: 0.6120\n","Val Metrics: Precision=0.5896, Recall=0.5584, F1=0.5503\n","Epoch 17/30 - Train Loss: 0.6283 - Val Loss: 0.6130\n","Val Metrics: Precision=0.5869, Recall=0.5592, F1=0.5526\n","Epoch 18/30 - Train Loss: 0.6286 - Val Loss: 0.6187\n","Val Metrics: Precision=0.5937, Recall=0.5337, F1=0.4961\n","Epoch 19/30 - Train Loss: 0.6264 - Val Loss: 0.6126\n","Val Metrics: Precision=0.5868, Recall=0.5559, F1=0.5469\n","Epoch 20/30 - Train Loss: 0.6260 - Val Loss: 0.6226\n","Val Metrics: Precision=0.5982, Recall=0.5295, F1=0.4838\n","Epoch 21/30 - Train Loss: 0.6250 - Val Loss: 0.6132\n","Val Metrics: Precision=0.5910, Recall=0.5505, F1=0.5347\n","Epoch 22/30 - Train Loss: 0.6235 - Val Loss: 0.6196\n","Val Metrics: Precision=0.5911, Recall=0.5815, F1=0.5832\n","Epoch 23/30 - Train Loss: 0.6240 - Val Loss: 0.6218\n","Val Metrics: Precision=0.5964, Recall=0.5905, F1=0.5922\n","Epoch 24/30 - Train Loss: 0.6228 - Val Loss: 0.6211\n","Val Metrics: Precision=0.5923, Recall=0.5841, F1=0.5859\n","Epoch 25/30 - Train Loss: 0.6213 - Val Loss: 0.6174\n","Val Metrics: Precision=0.5848, Recall=0.5693, F1=0.5691\n","Epoch 26/30 - Train Loss: 0.6209 - Val Loss: 0.6174\n","Val Metrics: Precision=0.5895, Recall=0.5741, F1=0.5746\n","Epoch 27/30 - Train Loss: 0.6204 - Val Loss: 0.6144\n","Val Metrics: Precision=0.5882, Recall=0.5630, F1=0.5586\n","Epoch 28/30 - Train Loss: 0.6211 - Val Loss: 0.6150\n","Val Metrics: Precision=0.5874, Recall=0.5498, F1=0.5350\n","Epoch 29/30 - Train Loss: 0.6187 - Val Loss: 0.6309\n","Val Metrics: Precision=0.5974, Recall=0.5993, F1=0.5982\n","Epoch 30/30 - Train Loss: 0.6184 - Val Loss: 0.6186\n","Val Metrics: Precision=0.5900, Recall=0.5771, F1=0.5783\n","\n","Test Results:\n","Loss: 0.5237\n","Precision: 0.6687\n","Recall: 0.6564\n","F1 Score: 0.6619\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/av_sv_fp_energy_efficiency_linear_model.pth\n","saved!\n","\n","\n","ablation: sv_lst_fp\n","Training data shape: (27922, 2052)\n","Training labels shape: (27922,)\n","Validation data shape: (2805, 2052)\n","Test data shape: (2756, 2052)\n","distribution: efficient=18198, inefficient=9724\n","weights: efficient=0.7672, inefficient=1.4357\n","Epoch 1/30 - Train Loss: 0.6812 - Val Loss: 0.6791\n","Val Metrics: Precision=0.5821, Recall=0.5902, F1=0.5660\n","Epoch 2/30 - Train Loss: 0.6685 - Val Loss: 0.6724\n","Val Metrics: Precision=0.5893, Recall=0.5985, F1=0.5782\n","Epoch 3/30 - Train Loss: 0.6643 - Val Loss: 0.6878\n","Val Metrics: Precision=0.5938, Recall=0.5997, F1=0.5597\n","Epoch 4/30 - Train Loss: 0.6616 - Val Loss: 0.6574\n","Val Metrics: Precision=0.5883, Recall=0.5957, F1=0.5871\n","Epoch 5/30 - Train Loss: 0.6591 - Val Loss: 0.6887\n","Val Metrics: Precision=0.5973, Recall=0.6021, F1=0.5582\n","Epoch 6/30 - Train Loss: 0.6575 - Val Loss: 0.6433\n","Val Metrics: Precision=0.5908, Recall=0.5927, F1=0.5915\n","Epoch 7/30 - Train Loss: 0.6557 - Val Loss: 0.6458\n","Val Metrics: Precision=0.5892, Recall=0.5933, F1=0.5902\n","Epoch 8/30 - Train Loss: 0.6545 - Val Loss: 0.6509\n","Val Metrics: Precision=0.5924, Recall=0.5995, F1=0.5923\n","Epoch 9/30 - Train Loss: 0.6528 - Val Loss: 0.6502\n","Val Metrics: Precision=0.5925, Recall=0.5995, F1=0.5924\n","Epoch 10/30 - Train Loss: 0.6516 - Val Loss: 0.6806\n","Val Metrics: Precision=0.6073, Recall=0.6154, F1=0.5784\n","Epoch 11/30 - Train Loss: 0.6508 - Val Loss: 0.6854\n","Val Metrics: Precision=0.6060, Recall=0.6129, F1=0.5727\n","Epoch 12/30 - Train Loss: 0.6501 - Val Loss: 0.6476\n","Val Metrics: Precision=0.5906, Recall=0.5971, F1=0.5908\n","Epoch 13/30 - Train Loss: 0.6486 - Val Loss: 0.6407\n","Val Metrics: Precision=0.5903, Recall=0.5938, F1=0.5914\n","Epoch 14/30 - Train Loss: 0.6481 - Val Loss: 0.6473\n","Val Metrics: Precision=0.5935, Recall=0.6004, F1=0.5935\n","Epoch 15/30 - Train Loss: 0.6467 - Val Loss: 0.6343\n","Val Metrics: Precision=0.5978, Recall=0.5966, F1=0.5972\n","Epoch 16/30 - Train Loss: 0.6460 - Val Loss: 0.6364\n","Val Metrics: Precision=0.5969, Recall=0.5983, F1=0.5975\n","Epoch 17/30 - Train Loss: 0.6454 - Val Loss: 0.6311\n","Val Metrics: Precision=0.5972, Recall=0.5945, F1=0.5956\n","Epoch 18/30 - Train Loss: 0.6450 - Val Loss: 0.6218\n","Val Metrics: Precision=0.5971, Recall=0.5822, F1=0.5836\n","Epoch 19/30 - Train Loss: 0.6433 - Val Loss: 0.6661\n","Val Metrics: Precision=0.6034, Recall=0.6139, F1=0.5906\n","Epoch 20/30 - Train Loss: 0.6435 - Val Loss: 0.6347\n","Val Metrics: Precision=0.5957, Recall=0.5972, F1=0.5964\n","Epoch 21/30 - Train Loss: 0.6430 - Val Loss: 0.6310\n","Val Metrics: Precision=0.5984, Recall=0.5969, F1=0.5975\n","Epoch 22/30 - Train Loss: 0.6418 - Val Loss: 0.6211\n","Val Metrics: Precision=0.5972, Recall=0.5832, F1=0.5847\n","Epoch 23/30 - Train Loss: 0.6411 - Val Loss: 0.6545\n","Val Metrics: Precision=0.5958, Recall=0.6051, F1=0.5918\n","Epoch 24/30 - Train Loss: 0.6408 - Val Loss: 0.6462\n","Val Metrics: Precision=0.5911, Recall=0.5980, F1=0.5909\n","Epoch 25/30 - Train Loss: 0.6400 - Val Loss: 0.6218\n","Val Metrics: Precision=0.6026, Recall=0.5895, F1=0.5915\n","Epoch 26/30 - Train Loss: 0.6394 - Val Loss: 0.6194\n","Val Metrics: Precision=0.6041, Recall=0.5866, F1=0.5882\n","Epoch 27/30 - Train Loss: 0.6387 - Val Loss: 0.6215\n","Val Metrics: Precision=0.6017, Recall=0.5894, F1=0.5915\n","Epoch 28/30 - Train Loss: 0.6386 - Val Loss: 0.6243\n","Val Metrics: Precision=0.6072, Recall=0.5991, F1=0.6014\n","Epoch 29/30 - Train Loss: 0.6374 - Val Loss: 0.6415\n","Val Metrics: Precision=0.5921, Recall=0.5981, F1=0.5927\n","Epoch 30/30 - Train Loss: 0.6375 - Val Loss: 0.6320\n","Val Metrics: Precision=0.5996, Recall=0.6010, F1=0.6002\n","\n","Test Results:\n","Loss: 0.5253\n","Precision: 0.6520\n","Recall: 0.6030\n","F1 Score: 0.6150\n","path: /content/drive/MyDrive/semester 4/csci 1470: final project/ablation_models/sv_lst_fp_energy_efficiency_linear_model.pth\n","saved!\n","\n","\n"]}]},{"cell_type":"code","source":["print(\"\\nPerformance Comparison:\")\n","print(f\"Linear Head - F1: {linear_metrics['f1']:.4f}, Precision: {linear_metrics['precision']:.4f}, Recall: {linear_metrics['recall']:.4f}\")\n","print(f\"MLP Head - F1: {test_metrics['f1']:.4f}, Precision: {test_metrics['precision']:.4f}, Recall: {test_metrics['recall']:.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"i03sl7ySik4u","executionInfo":{"status":"ok","timestamp":1745809911963,"user_tz":240,"elapsed":96,"user":{"displayName":"Eric Zheng","userId":"09751706780638879012"}},"outputId":"c379ff12-8f48-45d2-cb7b-222cae0a1119"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Performance Comparison:\n","Linear Head - F1: 0.6242, Precision: 0.6818, Recall: 0.6091\n","MLP Head - F1: 0.6694, Precision: 0.6704, Recall: 0.6684\n"]}]}]}